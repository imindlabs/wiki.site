<!DOCTYPE HTML>
<html lang="en" >
    <head><meta charset="UTF-8">
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"><title>2. Filters · Intelligent Mind Labs</title><meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="description" content="Wikis for Data Science, Computing, Software Development, Math, etc.
"><!-- <meta name="generator" content="Jekyll (using style of GitBook 3.2.3)"> --><meta name="author" content="Intelligent Mind Labs"><!-- <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script> -->
<!-- <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.7.1/jquery.min.js"></script> -->

<!-- For logo animation -->
<!-- <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/animate.css/4.1.1/animate.min.css"> -->

<link rel="stylesheet" href="/ds/aml/assets/fonts/fa5.15/css/all.min.css">

<link id="gitbook_style" rel="stylesheet" href="/ds/aml/assets/gitbook/style.css">
<link rel="stylesheet" href="/ds/aml/assets/gitbook/gitbook-plugin-back-to-top-button/plugin.css">
<link rel="stylesheet" href="/ds/aml/assets/gitbook/gitbook-plugin-expandable-chapters-small2/expandable-chapters-small.css">
<link rel="stylesheet" href="/ds/aml/assets/gitbook/gitbook-plugin-fontsettings/website.css">
<link rel="stylesheet" href="/ds/aml/assets/gitbook/gitbook-plugin-search-pro/search.css">
<link rel="stylesheet" href="/ds/aml/assets/gitbook/gitbook-plugin-splitter/splitter.css">



<!-- <link rel="stylesheet" href="/ds/aml/assets/gitbook/rouge/colorful.css"> -->

<style>
@import url('https://fonts.googleapis.com/css2?family=Exo:ital,wght@0,100..900;1,100..900&display=swap');
</style>
    

<link rel="stylesheet" href="/ds/aml/assets/gitbook/custom.css">
<link rel="stylesheet" href="/ds/aml/assets/gitbook/custom-local.css"><style>
.img_url {
    content: url("/ds/aml/assets/images/wiki.imindlabs.grey.logo.png");
}

.book.color-theme-2 .img_url {
    content: url("/ds/aml/assets/images/wiki.imindlabs.logo.png");
}
</style><link rel="stylesheet" href="/ds/aml/assets/gitbook/custom-local-child.css">

<meta name="HandheldFriendly" content="true"/>
<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black">
<!-- <link rel="apple-touch-icon-precomposed" sizes="152x152" href="/ds/aml/assets/gitbook/images/apple-touch-icon-precomposed-152.png"> -->
<!-- <link rel="shortcut icon" href="/ds/aml/wiki.imindlabs.favicon.png" type="image/x-icon"> -->
<link rel="apple-touch-icon-precomposed" sizes="152x152" href="/ds/aml/wiki.imindlabs.favicon.png">
<link rel="icon" href="/ds/aml/wiki.imindlabs.favicon.png" sizes="32x32" type="image/png">
<link rel="icon" href="/ds/aml/wiki.imindlabs.favicon.png" sizes="16x16" type="image/png">
<link rel="shortcut icon" href="/ds/aml/wiki.imindlabs.favicon.png" type="image/png">



<!-- trackers -->
            <link rel="prev" href="/ds/aml/basics/1_ima_1_basics/" />
        

        
            <link rel="next" href="/ds/aml/image_analysis/1_ima_3_edge_detectors/" />
        
    </head>
    <body>         
        <div class="book"><div class="book-summary">
    <script type="text/javascript">
        // Fixes the page links scroll problem on both desktop and mobile browsers
        function pageScrollToTop(element) {
            // both mobile and non-mobile
            $('div.body-inner').animate({ scrollTop: 0 });
            $(element).parent().find('li>ul>li').removeClass('active');
            return true;  // propagate
        }
        // Fixes the anchor links scroll problem on mobile browsers
        function mobilePageScrollToAnchor(element) {
            $(element).closest('li.chapter').find('ul>li').removeClass('active');
            $(element).parent().addClass('active');
            
            // ! BUG: Enable the following functionality on large screen sizes
            // On sub menu item click the page did not navigate. Now it does.
            //if ($(document).width() <= 1240) {
                $('div.body-inner').animate({ scrollTop: $($(element).attr('href')).get(0).offsetTop });
            // }
            return true;
        }
    </script>

    <!-- <div style="text-align:center;" class="animate__animated animate__pulse animate__delay-1s">
        <a href="/ds/aml/">
            <img class="logo zoom" src="/ds/aml/assets/images/wiki.imindlabs.logo.png" alt="Intelligent Mind Labs wiki logo" />
        </a>
    </div> -->
    <div style="text-align:center;" class="logo-wrap">
        <a href="/ds/aml/">
            <img class="logo zoom" src="/ds/aml/assets/images/wiki.imindlabs.logo_153x200.webp" alt="Intelligent Mind Labs wiki logo" width="153" height="200"/>
        </a>
    </div>

    <nav role="navigation">
        <div id="book-search-input" role="search">
            <input type="text" placeholder="Type to search" />
        </div>
        <div id="book-search-input-link" role="search">
            <a href="/ds/aml/assets/search.html">Click to Search</a>
        </div>
        <ul class="summary">
            
            <li class="chapter" data-level="1.1" data-path="/ds/aml">
                
                <a href="/ds/aml/" onclick="pageScrollToTop(this)">
                    Wiki | Advance Machine Learning
                </a>
            </li>

            <!-- <li class="divider"></li> -->

            
            <!-- <p>1_learning_domains</p> -->
            
                <p class="collection-title">Learning Domains</p>
            
            
            

            

            
            
            
            <!-- <p>2_dataset_preparation</p> -->
            
                <p class="collection-title">Dataset Preparation</p>
            
            
            

            

            
            
            
            <!-- <p>3_feature_analysis</p> -->
            
                <p class="collection-title">Feature Analysis</p>
            
            
            

            

            
            
            
            <!-- <p>4_problem_domains</p> -->
            
                <p class="collection-title">Problem Domains</p>
            
            
            

            
            
            
            <p class="separator-title">Image Processing</p>
            
            
            
            <li class="chapter" data-level="1.1" data-path="/ds/aml/basics/1_ima_1_basics/">
                
                <a href="/ds/aml/basics/1_ima_1_basics/" onclick="pageScrollToTop(this)">
                    1. Introduction
                </a>
                
                
                
            </li>
            
            
            
            
            
            <li class="chapter active" data-level="1.2" data-path="/ds/aml/image_analysis/1_ima_2_filters/">
                
                <a href="/ds/aml/image_analysis/1_ima_2_filters/" onclick="pageScrollToTop(this)">
                    2. Filters
                </a>
                
                
                <ul><li><a href="#1-linear-filters" onclick="mobilePageScrollToAnchor(this)" >1. Linear Filters</a><ul><li><a href="#11-how-linear-filters-work" onclick="mobilePageScrollToAnchor(this)" >1.1 How Linear Filters Work</a></li><li><a href="#12-common-linear-filters" onclick="mobilePageScrollToAnchor(this)" >1.2 Common Linear Filters</a></li><li><a href="#13-applications-of-linear-filters-in-machine-learning" onclick="mobilePageScrollToAnchor(this)" >1.3 Applications of Linear Filters in Machine Learning</a></li><li><a href="#14-keypoints" onclick="mobilePageScrollToAnchor(this)" >1.4 Keypoints</a></li></ul></li><li><a href="#2-image-gradient" onclick="mobilePageScrollToAnchor(this)" >2. Image Gradient</a><ul><li><a href="#21-key-concepts" onclick="mobilePageScrollToAnchor(this)" >2.1 Key Concepts</a></li><li><a href="#22-how-to-compute-the-gradient" onclick="mobilePageScrollToAnchor(this)" >2.2 How to Compute the Gradient:</a></li><li><a href="#23-implementation" onclick="mobilePageScrollToAnchor(this)" >2.3 Implementation</a></li></ul></li><li><a href="#3-image-gradient-corelation-ixiy" onclick="mobilePageScrollToAnchor(this)" >3. Image Gradient Corelation <code class="language-plaintext highlighter-rouge">Ix.Iy</code></a><ul><li><a href="#31-steps-to-calculate-i_xy" onclick="mobilePageScrollToAnchor(this)" >3.1 Steps to Calculate \(I_{xy}\)</a></li><li><a href="#32-implementation" onclick="mobilePageScrollToAnchor(this)" >3.2 Implementation</a></li></ul></li><li><a href="#4-median-filter" onclick="mobilePageScrollToAnchor(this)" >4. Median Filter</a><ul><li><a href="#41-how-the-median-filter-works" onclick="mobilePageScrollToAnchor(this)" >4.1 How the Median Filter Works</a></li><li><a href="#42-example-median-filter-application" onclick="mobilePageScrollToAnchor(this)" >4.2 Example: Median Filter Application</a></li><li><a href="#43-importance-of-median-filter-in-computer-vision" onclick="mobilePageScrollToAnchor(this)" >4.3 Importance of Median Filter in Computer Vision</a></li><li><a href="#44-usage" onclick="mobilePageScrollToAnchor(this)" >4.4 Usage</a></li><li><a href="#45-keypoints" onclick="mobilePageScrollToAnchor(this)" >4.5 Keypoints</a></li></ul></li><li><a href="#5-non-linear-filters" onclick="mobilePageScrollToAnchor(this)" >5. Non-linear Filters</a><ul><li><a href="#51-common-non-linear-filters-in-computer-vision" onclick="mobilePageScrollToAnchor(this)" >5.1 Common Non-Linear Filters in Computer Vision</a></li><li><a href="#52-importance-of-non-linear-filters-in-computer-vision" onclick="mobilePageScrollToAnchor(this)" >5.2 Importance of Non-Linear Filters in Computer Vision</a></li><li><a href="#53-usage" onclick="mobilePageScrollToAnchor(this)" >5.3 Usage</a></li><li><a href="#54-keypoints" onclick="mobilePageScrollToAnchor(this)" >5.4 Keypoints</a></li></ul></li></ul>

                
                
            </li>
            
            
            
            
            
            <li class="chapter" data-level="1.1" data-path="/ds/aml/image_analysis/1_ima_3_edge_detectors/">
                
                <a href="/ds/aml/image_analysis/1_ima_3_edge_detectors/" onclick="pageScrollToTop(this)">
                    3. Edge Detectors
                </a>
                
                
                
            </li>
            
            
            
            
            
            <li class="chapter" data-level="1.1" data-path="/ds/aml/image_analysis/1_ima_4_corner_detectors/">
                
                <a href="/ds/aml/image_analysis/1_ima_4_corner_detectors/" onclick="pageScrollToTop(this)">
                    4. Corner Detectors
                </a>
                
                
                
            </li>
            
            
            
            
            
            <li class="chapter" data-level="1.1" data-path="/ds/aml/image_analysis/1_ima_5_region_detectors/">
                
                <a href="/ds/aml/image_analysis/1_ima_5_region_detectors/" onclick="pageScrollToTop(this)">
                    5. Region Detectors
                </a>
                
                
                
            </li>
            
            
            
            <p class="separator-title">Regression</p>
            
            
            
            <li class="chapter" data-level="1.1" data-path="/ds/aml/basics/1_regression_1_cv/">
                
                <a href="/ds/aml/basics/1_regression_1_cv/" onclick="pageScrollToTop(this)">
                    1. Computer Vision
                </a>
                
                
                
            </li>
            
            
            
            
            
            <li class="chapter" data-level="1.1" data-path="/ds/aml/basics/1_regression_1_nlp/">
                
                <a href="/ds/aml/basics/1_regression_1_nlp/" onclick="pageScrollToTop(this)">
                    2. Natural Language Processing
                </a>
                
                
                
            </li>
            

            
            <!-- <li class="divider"></li> -->
            
            
            
            <!-- <p>posts</p> -->
            
            
            

            

            
            
            
        </ul>
    </nav>
</div><div class="book-body">
                <div class="book-header" role="navigation">
                    <!-- Title -->
                    <h1>
                        <i class="fa fa-circle-o-notch fa-spin"></i>
                        
                            <a href="." >2. Filters</a>
                        
                    </h1>
                </div>

                <div class="body-inner"><div class="page-wrapper" tabindex="-1" role="main">
    

    <!-- <div class="spinner-container">
        <div class="spinner-border text-info" role="status">
            <span class="visually-hidden">Loading...</span>
        </div>
    </div> -->

    <div class="page-inner">
        <div id="book-search-results"> <!-- class="hide_element" -->            
            <div class="search-noresults">
                <section class="normal markdown-section">
                    
                        <h1 id="/image_analysis/1_ima_2_filters">2. Filters</h1>
                    

                    <h1 id="1-linear-filters">1. Linear Filters</h1>

<p>Linear filters are fundamental tools in image processing and computer vision. They involve the application of a convolution operation to an image using a kernel (or filter). This operation produces a new image where each pixel value is computed as a weighted sum of its neighboring pixels, defined by the kernel. Linear filters are used for a variety of tasks such as blurring, sharpening, edge detection, and noise reduction.</p>

<h2 id="11-how-linear-filters-work">1.1 How Linear Filters Work</h2>

<p><strong>1. Kernel (Filter) Matrix</strong>:</p>
<ul>
  <li>A kernel is a small matrix (usually 3x3, 5x5, etc.) that is applied to each pixel in the image.</li>
  <li>The kernel defines the weights that will be multiplied by the pixel values in the neighborhood of the pixel being processed.</li>
</ul>

<p><strong>2. Convolution Operation</strong>:</p>
<ul>
  <li>Convolution involves sliding the kernel over the image and computing the weighted sum of the pixel values covered by the kernel.</li>
  <li>The center of the kernel is aligned with each pixel in the image, and the result of the convolution replaces the original pixel value.</li>
  <li>Mathematically, if \(I(x, y)\) is the image and \(K(i, j)\) is the kernel, the convolution \(I'\) at a point \((x, y)\) is given by:
\(I'(x, y) = \sum_{i=-n}^{n} \sum_{j=-n}^{n} I(x+i, y+j) \cdot K(i, j)\)</li>
  <li>Here, \(n\) is half the width/height of the kernel.</li>
</ul>

<h2 id="12-common-linear-filters">1.2 Common Linear Filters</h2>

<p><strong>1. Box Filter (Averaging Filter)</strong>:</p>
<ul>
  <li>Kernel: A matrix with equal values that sum to 1.</li>
  <li>Effect: Smooths the image by averaging the pixel values within the neighborhood.</li>
  <li>Example kernel:
\(\frac{1}{9}
\begin{bmatrix}
1 &amp; 1 &amp; 1 \\
1 &amp; 1 &amp; 1 \\
1 &amp; 1 &amp; 1
\end{bmatrix}\)</li>
</ul>

<p><strong>2. Gaussian Filter</strong>:</p>
<ul>
  <li>Kernel: Values follow a Gaussian distribution, giving more weight to the center pixels.</li>
  <li>Effect: Smooths the image with a Gaussian blur, preserving edges better than the box filter.</li>
  <li>Example kernel (3x3 with \(\sigma = 1\)):
\(\frac{1}{16}
\begin{bmatrix}
1 &amp; 2 &amp; 1 \\
2 &amp; 4 &amp; 2 \\
1 &amp; 2 &amp; 1
\end{bmatrix}\)</li>
</ul>

<p><strong>3. Sobel Filter</strong>:</p>
<ul>
  <li>Kernel: Specifically designed for edge detection, with separate kernels for detecting horizontal and vertical edges.</li>
  <li>Effect: Highlights edges in the image by computing the gradient magnitude.</li>
  <li>Example kernels (for horizontal and vertical edges):
\(K_x = \begin{bmatrix}
-1 &amp; 0 &amp; 1 \\
-2 &amp; 0 &amp; 2 \\
-1 &amp; 0 &amp; 1
\end{bmatrix}, \quad
K_y = \begin{bmatrix}
-1 &amp; -2 &amp; -1 \\
0 &amp; 0 &amp; 0 \\
1 &amp; 2 &amp; 1
\end{bmatrix}\)</li>
</ul>

<p><strong>4. Prewitt Filter</strong>:</p>
<ul>
  <li>Kernel: Similar to Sobel, but with slightly different weights.</li>
  <li>Effect: Another method for edge detection, emphasizing vertical or horizontal gradients.</li>
  <li>Example kernels:
\(K_x = \begin{bmatrix}
-1 &amp; 0 &amp; 1 \\
-1 &amp; 0 &amp; 1 \\
-1 &amp; 0 &amp; 1
\end{bmatrix}, \quad
K_y = \begin{bmatrix}
-1 &amp; -1 &amp; -1 \\
0 &amp; 0 &amp; 0 \\
1 &amp; 1 &amp; 1
\end{bmatrix}\)</li>
</ul>

<p><strong>5. Laplacian Filter</strong>:</p>
<ul>
  <li>Kernel: A second-order derivative operator that detects edges by measuring the rate of change in intensity.</li>
  <li>Effect: Highlights regions of rapid intensity change (edges).</li>
  <li>Example kernel:
\(\begin{bmatrix}
0 &amp; -1 &amp; 0 \\
-1 &amp; 4 &amp; -1 \\
0 &amp; -1 &amp; 0
\end{bmatrix}\)</li>
</ul>

<p><strong>6. Sharpening Filter</strong>:</p>
<ul>
  <li>Kernel: Emphasizes differences between a pixel and its neighbors, enhancing edges.</li>
  <li>Effect: Makes edges and fine details in an image more pronounced.</li>
  <li>Example kernel:
\(\begin{bmatrix}
0 &amp; -1 &amp; 0 \\
-1 &amp; 5 &amp; -1 \\
0 &amp; -1 &amp; 0
\end{bmatrix}\)</li>
</ul>

<h2 id="13-applications-of-linear-filters-in-machine-learning">1.3 Applications of Linear Filters in Machine Learning</h2>

<p><strong>1. Preprocessing</strong>:</p>
<ul>
  <li>Linear filters can be used to preprocess images before feeding them into machine learning models. For example, Gaussian filters can reduce noise, while edge-detection filters like Sobel can highlight important features.</li>
</ul>

<p><strong>2. Feature Extraction</strong>:</p>
<ul>
  <li>Filters like Sobel and Prewitt can extract edge features, which can then be used as input features for models in tasks like object detection, image segmentation, and facial recognition.</li>
</ul>

<p><strong>3. Image Augmentation</strong>:</p>
<ul>
  <li>Applying different linear filters to images can create augmented datasets that help models generalize better by learning from various image representations.</li>
</ul>

<p><strong>4. Noise Reduction</strong>:</p>
<ul>
  <li>Filters like Gaussian and median filters are used to reduce noise in images, making it easier for models to learn from clean, relevant features.</li>
</ul>

<p><strong>5. Enhancing Model Interpretability</strong>:</p>
<ul>
  <li>Linear filters can help in visualizing what parts of the image are most important for model decisions, especially in tasks like saliency mapping or visualization of convolutional neural networks (CNNs).</li>
</ul>

<h2 id="14-keypoints">1.4 Keypoints</h2>
<ul>
  <li><strong>Linear filters</strong> are used to modify images by applying convolution with a kernel.</li>
  <li><strong>Different filters</strong> serve different purposes, like blurring, sharpening, or edge detection.</li>
  <li><strong>In machine learning</strong>, linear filters are crucial for preprocessing, feature extraction, noise reduction, and data augmentation, all of which contribute to better model performance in computer vision tasks.</li>
</ul>

<h1 id="2-image-gradient">2. Image Gradient</h1>

<p>An image gradient is a directional change in the intensity or color in an image. It is a fundamental concept in image processing and computer vision, often used for edge detection, texture analysis, and object recognition. The gradient of an image measures how much and in which direction the intensity of the image is changing.</p>

<h2 id="21-key-concepts">2.1 Key Concepts</h2>

<p><strong>1. Gradient at a Pixel:</strong></p>
<ul>
  <li>At a given pixel in an image, the gradient is a vector that points in the direction of the greatest rate of increase of intensity. The magnitude of this vector indicates the strength of the change, while the direction indicates the orientation of the edge or transition in the image.</li>
</ul>

<p><strong>2. Gradient Components:</strong></p>
<ul>
  <li>The image gradient is typically described by its components in the \(x\) (horizontal) and \(y\) (vertical) directions:
\(\nabla I = \left[ \frac{\partial I}{\partial x}, \frac{\partial I}{\partial y} \right]\)
    <ul>
      <li>\(\frac{\partial I}{\partial x}\) (denoted as \(I_x\)) is the gradient in the \(x\) direction.</li>
      <li>\(\frac{\partial I}{\partial y}\) (denoted as \(I_y\)) is the gradient in the \(y\) direction.</li>
    </ul>
  </li>
</ul>

<p><strong>3. Magnitude and Direction of Gradient:</strong></p>
<ul>
  <li>The magnitude of the gradient is given by:
\(\text{Magnitude} = \sqrt{I_x^2 + I_y^2}\)</li>
  <li>The direction (angle) of the gradient is given by:
\(\text{Direction} = \theta = \arctan\left(\frac{I_y}{I_x}\right)\)</li>
</ul>

<p><strong>4. Edge Detection:</strong></p>
<ul>
  <li>Gradients are commonly used in corner and edge detection algorithms because edges in an image are typically locations of high intensity change. The magnitude of the gradient will be high at edges and low in flat regions.</li>
</ul>

<h2 id="22-how-to-compute-the-gradient">2.2 How to Compute the Gradient:</h2>

<p>The image gradient is usually computed using convolution with derivative kernels such as the Sobel operator, Prewitt operator, or Scharr operator.</p>

<h4 id="sobel-operator">Sobel Operator:</h4>
<p>The Sobel operator is one of the most widely used methods to compute the gradient in an image. It uses convolution with the following kernels to calculate \(I_x\) and \(I_y\):</p>

<ul>
  <li>
    <p><strong>Gradient in the \(x\) direction (horizontal):</strong>
\(I_x = \begin{bmatrix}
-1 &amp; 0 &amp; +1 \\
-2 &amp; 0 &amp; +2 \\
-1 &amp; 0 &amp; +1
\end{bmatrix}\)</p>
  </li>
  <li>
    <p><strong>Gradient in the \(y\) direction (vertical):</strong>
\(I_y = \begin{bmatrix}
-1 &amp; -2 &amp; -1 \\
0 &amp; 0 &amp; 0 \\
+1 &amp; +2 &amp; +1
\end{bmatrix}\)</p>
  </li>
</ul>

<h2 id="23-implementation">2.3 Implementation</h2>

<p>Here’s how you can compute the gradient of an image using the Sobel operator in OpenCV:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">cv2</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="c1"># Load the image in grayscale
</span><span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">imread</span><span class="p">(</span><span class="sh">'</span><span class="s">path_to_your_image.jpg</span><span class="sh">'</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">IMREAD_GRAYSCALE</span><span class="p">)</span>

<span class="c1"># Compute the gradient in the x direction (horizontal edges)
</span><span class="n">I_x</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nc">Sobel</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">CV_64F</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">ksize</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="c1"># Compute the gradient in the y direction (vertical edges)
</span><span class="n">I_y</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nc">Sobel</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">CV_64F</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">ksize</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="c1"># Compute the gradient magnitude
</span><span class="n">magnitude</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">I_x</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">I_y</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># Compute the gradient direction
</span><span class="n">direction</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">arctan2</span><span class="p">(</span><span class="n">I_y</span><span class="p">,</span> <span class="n">I_x</span><span class="p">)</span>

<span class="c1"># Display the results
</span><span class="n">plt</span><span class="p">.</span><span class="nf">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">plt</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="n">I_x</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="sh">'</span><span class="s">gray</span><span class="sh">'</span><span class="p">),</span> <span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Gradient X</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">plt</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="n">I_y</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="sh">'</span><span class="s">gray</span><span class="sh">'</span><span class="p">),</span> <span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Gradient Y</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">plt</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="n">magnitude</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="sh">'</span><span class="s">gray</span><span class="sh">'</span><span class="p">),</span> <span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Gradient Magnitude</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div>

<h1 id="3-image-gradient-corelation-ixiy">3. Image Gradient Corelation <code class="language-plaintext highlighter-rouge">Ix.Iy</code></h1>

<p>In the Harris Corner Detection algorithm, \(I_{xy}\) represents the product of the gradients in the \(x\) and \(y\) directions at each pixel. The gradients \(I_x\) and \(I_y\) are computed using derivative operations on the image, typically with the Sobel operator. The steps to calculate \(I_{xy}\) are as follows:</p>

<h2 id="31-steps-to-calculate-i_xy">3.1 Steps to Calculate \(I_{xy}\)</h2>

<p><strong>1. Compute Image Gradients \(I_x\) and \(I_y\):</strong></p>
<ul>
  <li>
    <p>The image gradients represent the rate of change in pixel intensity in the \(x\) and \(y\) directions. They can be calculated using the Sobel operator, which is a common method to approximate the derivative.</p>
  </li>
  <li>
    <p><strong>Gradient in the \(x\) direction (\(I_x\))</strong>:
\(I_x = \frac{\partial I}{\partial x}\)
The Sobel filter for \(I_x\) is:
\(\text{Sobel}_x = \begin{bmatrix}
-1 &amp; 0 &amp; +1 \\
-2 &amp; 0 &amp; +2 \\
-1 &amp; 0 &amp; +1
\end{bmatrix}\)</p>
  </li>
  <li>
    <p><strong>Gradient in the \(y\) direction (\(I_y\))</strong>:
\(I_y = \frac{\partial I}{\partial y}\)
The Sobel filter for \(I_y\) is:
\(\text{Sobel}_y = \begin{bmatrix}
-1 &amp; -2 &amp; -1 \\
0 &amp; 0 &amp; 0 \\
+1 &amp; +2 &amp; +1
\end{bmatrix}\)</p>
  </li>
</ul>

<p><strong>2. Calculate \(I_{xy}\):</strong></p>
<ul>
  <li>Once you have the gradients \(I_x\) and \(I_y\), you calculate \(I_{xy}\) as the product of these two gradients at each pixel:
\(I_{xy} = I_x \cdot I_y\)</li>
</ul>

<h2 id="32-implementation">3.2 Implementation</h2>

<p>In OpenCV, you can compute \(I_{xy}\) using the following steps:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">cv2</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="c1"># Load the image and convert it to grayscale
</span><span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">imread</span><span class="p">(</span><span class="sh">'</span><span class="s">path_to_your_image.jpg</span><span class="sh">'</span><span class="p">)</span>
<span class="n">gray</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">cvtColor</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">COLOR_BGR2GRAY</span><span class="p">)</span>

<span class="c1"># Compute gradients in the x and y direction using Sobel operator
</span><span class="n">I_x</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nc">Sobel</span><span class="p">(</span><span class="n">gray</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">CV_64F</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">ksize</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">I_y</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nc">Sobel</span><span class="p">(</span><span class="n">gray</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">CV_64F</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">ksize</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="c1"># Compute the product of the gradients (Ixy)
</span><span class="n">I_xy</span> <span class="o">=</span> <span class="n">I_x</span> <span class="o">*</span> <span class="n">I_y</span>

<span class="c1"># I_{xy} captures the correlation between the gradients 
# in the x and y directions, which is a crucial component in 
# forming the structure tensor M used in the 
# Harris Corner Detection algorithm.
</span></code></pre></div></div>

<ul>
  <li><strong><code class="language-plaintext highlighter-rouge">cv2.Sobel</code></strong>: This function computes the first derivative of the image in the specified direction.
    <ul>
      <li>The arguments <code class="language-plaintext highlighter-rouge">1, 0</code> and <code class="language-plaintext highlighter-rouge">0, 1</code> in <code class="language-plaintext highlighter-rouge">cv2.Sobel</code> specify the direction in which the gradient is computed.</li>
      <li><code class="language-plaintext highlighter-rouge">ksize=3</code> specifies the size of the Sobel kernel (3x3 in this case).</li>
    </ul>
  </li>
  <li>The gradients \(I_x\) and \(I_y\) are then multiplied to get \(I_{xy}\).</li>
</ul>

<h1 id="4-median-filter">4. Median Filter</h1>

<p>A <strong>median filter</strong> is a non-linear digital filtering technique commonly used in image processing to reduce noise while preserving edges in an image. Unlike linear filters, which compute the average of pixel values in the neighborhood, the median filter replaces the pixel value with the median value of the intensities in the neighborhood. This characteristic makes the median filter particularly effective at removing “salt-and-pepper” noise from images.</p>

<h2 id="41-how-the-median-filter-works">4.1 How the Median Filter Works</h2>

<p><strong>1. Kernel (Neighborhood) Definition</strong>:</p>
<ul>
  <li>A kernel, typically a square window (e.g., 3x3, 5x5), is defined around each pixel in the image.</li>
</ul>

<p><strong>2. Median Calculation</strong>:</p>
<ul>
  <li>For each pixel, the pixel values within the kernel are sorted, and the median value is identified.</li>
  <li>The median value is then assigned to the central pixel of the kernel.</li>
</ul>

<p><strong>3. Non-linear Operation</strong>:</p>
<ul>
  <li>The process is non-linear because the median operation does not involve any direct averaging or weighted sums like linear filters.</li>
</ul>

<h2 id="42-example-median-filter-application">4.2 Example: Median Filter Application</h2>

<p>Let’s consider a simple example using a 3x3 kernel:</p>

<h4 id="original-3x3-neighborhood">Original 3x3 Neighborhood:</h4>
<p>\(\begin{bmatrix}
10 &amp; 20 &amp; 10 \\
20 &amp; 500 &amp; 20 \\
10 &amp; 20 &amp; 10
\end{bmatrix}\)</p>

<ul>
  <li>The center pixel value is 500, which is a noise spike (assuming most pixels are around 10-20).</li>
  <li>The sorted list of values: \([10, 10, 10, 10, 20, 20, 20, 20, 500]\).</li>
  <li>The median value in this list is 20.</li>
</ul>

<h4 id="after-applying-the-median-filter">After Applying the Median Filter:</h4>
<p>\(\begin{bmatrix}
10 &amp; 20 &amp; 10 \\
20 &amp; \textbf{20} &amp; 20 \\
10 &amp; 20 &amp; 10
\end{bmatrix}\)</p>
<ul>
  <li>The center pixel value (previously 500) is replaced with 20, effectively removing the noise.</li>
</ul>

<h2 id="43-importance-of-median-filter-in-computer-vision">4.3 Importance of Median Filter in Computer Vision</h2>

<ol>
  <li><strong>Noise Reduction</strong>:
    <ul>
      <li>The primary application of the median filter is noise reduction, particularly for “salt-and-pepper” noise, which consists of random occurrences of white and black pixels. The median filter effectively removes this noise without blurring the edges.</li>
    </ul>
  </li>
  <li><strong>Edge Preservation</strong>:
    <ul>
      <li>Unlike linear filters like the mean filter, which can blur edges, the median filter preserves edges. This is crucial in computer vision tasks where edge information is important, such as in edge detection, object recognition, and image segmentation.</li>
    </ul>
  </li>
  <li><strong>Image Smoothing</strong>:
    <ul>
      <li>The median filter smooths an image by removing small details or outliers while keeping the overall structure intact. This is beneficial for tasks that require clean images, like template matching and pattern recognition.</li>
    </ul>
  </li>
  <li><strong>Preprocessing Step in Machine Learning</strong>:
    <ul>
      <li>In machine learning, especially in computer vision applications, the median filter is often used as a preprocessing step to clean the input images. This ensures that the models focus on relevant features rather than noise, leading to better accuracy and robustness.</li>
    </ul>
  </li>
  <li><strong>Application in Medical Imaging</strong>:
    <ul>
      <li>The median filter is widely used in medical imaging to reduce noise from imaging techniques like X-rays, MRI, and CT scans, where preserving edge details is crucial for accurate diagnosis.</li>
    </ul>
  </li>
  <li><strong>Real-Time Processing</strong>:
    <ul>
      <li>Due to its simplicity and effectiveness, the median filter is often used in real-time image processing applications, such as video surveillance and autonomous driving, where quick and reliable noise reduction is essential.</li>
    </ul>
  </li>
</ol>

<h2 id="44-usage">4.4 Usage</h2>

<p>Here’s how you can apply a median filter using OpenCV:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">cv2</span>

<span class="c1"># Load an image with noise
</span><span class="n">image</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">imread</span><span class="p">(</span><span class="sh">'</span><span class="s">noisy_image.jpg</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># Apply a median filter with a 5x5 kernel
</span><span class="n">filtered_image</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">medianBlur</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>

<span class="c1"># Display the original and filtered images
</span><span class="n">cv2</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="sh">'</span><span class="s">Original Image</span><span class="sh">'</span><span class="p">,</span> <span class="n">image</span><span class="p">)</span>
<span class="n">cv2</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="sh">'</span><span class="s">Median Filtered Image</span><span class="sh">'</span><span class="p">,</span> <span class="n">filtered_image</span><span class="p">)</span>

<span class="n">cv2</span><span class="p">.</span><span class="nf">waitKey</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">cv2</span><span class="p">.</span><span class="nf">destroyAllWindows</span><span class="p">()</span>
</code></pre></div></div>

<h2 id="45-keypoints">4.5 Keypoints</h2>

<ul>
  <li><strong>Median filter</strong>: A non-linear filter used to reduce noise while preserving edges in an image.</li>
  <li><strong>Key applications</strong>: Noise reduction, edge preservation, image smoothing, and preprocessing in computer vision tasks.</li>
  <li><strong>Importance</strong>: It is particularly effective against “salt-and-pepper” noise and is essential in tasks where edge preservation is critical, making it a go-to filter in many computer vision applications.</li>
</ul>

<h1 id="5-non-linear-filters">5. Non-linear Filters</h1>

<p>Non-linear filters are a class of image processing filters that operate on an image in a non-linear manner. Unlike linear filters, which apply a weighted sum or convolution to the pixels in a neighborhood, non-linear filters apply operations that are not linear in nature, such as finding the maximum, minimum, or median values within a neighborhood of pixels. These filters are particularly useful in preserving important features like edges while reducing noise and can address issues that linear filters struggle with, such as handling outliers and non-Gaussian noise.</p>

<h2 id="51-common-non-linear-filters-in-computer-vision">5.1 Common Non-Linear Filters in Computer Vision</h2>

<p><strong>1. Median Filter</strong>:</p>
<ul>
  <li><strong>Operation</strong>: Replaces each pixel’s value with the median of the neighboring pixel values.</li>
  <li><strong>Use Case</strong>: Excellent for removing “salt-and-pepper” noise while preserving edges. Unlike linear filters, it doesn’t blur edges, making it ideal for tasks where edge preservation is crucial.</li>
  <li><strong>Example Kernel</strong>: Typically a 3x3 or 5x5 window is used, but larger sizes can be used depending on the noise level.</li>
</ul>

<p><strong>2. Bilateral Filter</strong>:</p>
<ul>
  <li><strong>Operation</strong>: Applies a combination of Gaussian filtering in both the spatial domain and the intensity domain, preserving edges while smoothing the image.</li>
  <li><strong>Use Case</strong>: Used for edge-preserving smoothing, which is important in scenarios like denoising where edges should remain sharp.</li>
  <li><strong>Example Kernel</strong>: The filter considers both spatial closeness (pixels close to each other) and intensity similarity.</li>
</ul>

<p><strong>3. Min and Max Filters</strong>:</p>
<ul>
  <li><strong>Min Filter</strong>: Replaces each pixel with the minimum value in its neighborhood.</li>
  <li><strong>Max Filter</strong>: Replaces each pixel with the maximum value in its neighborhood.</li>
  <li><strong>Use Case</strong>: The Min filter can remove small bright details, while the Max filter can remove small dark details. These are useful for morphological operations like erosion and dilation in binary image processing.</li>
</ul>

<p><strong>4. Mode Filter</strong>:</p>
<ul>
  <li><strong>Operation</strong>: Replaces each pixel with the most frequently occurring value in its neighborhood.</li>
  <li><strong>Use Case</strong>: This filter is used when the goal is to remove outliers in a specific region while preserving the most common value. It is particularly useful in texture analysis and noise reduction.</li>
</ul>

<p><strong>5. Non-Local Means (NLM) Filter</strong>:</p>
<ul>
  <li><strong>Operation</strong>: Each pixel is replaced by a weighted average of similar pixels across the entire image, not just within a local neighborhood.</li>
  <li><strong>Use Case</strong>: Effective for noise reduction while preserving fine details, as it considers a larger context for filtering each pixel.</li>
  <li><strong>Example Application</strong>: Used in denoising algorithms where preserving high-frequency details is important, such as in medical imaging.</li>
</ul>

<p><strong>6. Adaptive Filters</strong>:</p>
<ul>
  <li><strong>Operation</strong>: Adjusts the filter behavior based on local image statistics (e.g., the variance within a neighborhood).</li>
  <li><strong>Use Case</strong>: Useful in scenarios where noise characteristics vary across the image, such as in adaptive smoothing or adaptive thresholding.</li>
  <li><strong>Example</strong>: Adaptive median filter, which changes the size of the neighborhood based on local conditions, can remove larger noise spikes while preserving edges.</li>
</ul>

<h2 id="52-importance-of-non-linear-filters-in-computer-vision">5.2 Importance of Non-Linear Filters in Computer Vision</h2>

<p><strong>1. Edge Preservation</strong>:</p>
<ul>
  <li>Non-linear filters like the median and bilateral filters are specifically designed to preserve edges while performing tasks like noise reduction. This is crucial in computer vision tasks like object recognition, where edges define important features.</li>
</ul>

<p><strong>2. Noise Reduction</strong>:</p>
<ul>
  <li>Non-linear filters excel at reducing various types of noise, including impulsive noise (e.g., “salt-and-pepper” noise) and speckle noise. This is vital in preparing images for further processing, such as segmentation or feature extraction.</li>
</ul>

<p><strong>3. Morphological Operations</strong>:</p>
<ul>
  <li>Filters like Min and Max are foundational in morphological image processing, which involves operations like dilation, erosion, opening, and closing. These operations are important in tasks such as shape analysis, object counting, and boundary extraction.</li>
</ul>

<p><strong>4. Handling Non-Gaussian Noise</strong>:</p>
<ul>
  <li>While linear filters are effective against Gaussian noise, non-linear filters are more versatile and can handle a wider range of noise types, including non-Gaussian and mixed noise types.</li>
</ul>

<p><strong>5. Image Smoothing and Detail Preservation</strong>:</p>
<ul>
  <li>Non-linear filters like the bilateral filter smooth images while retaining important details, which is important in applications like facial recognition and image compression, where both noise reduction and detail preservation are needed.</li>
</ul>

<p><strong>6. Adaptive Processing</strong>:</p>
<ul>
  <li>Non-linear filters can adapt their behavior based on local image characteristics, making them more effective in real-world applications where image properties can vary significantly across different regions.</li>
</ul>

<h2 id="53-usage">5.3 Usage</h2>

<p>Here’s an example of applying a median filter and a bilateral filter using OpenCV:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">cv2</span>

<span class="c1"># Load an image with noise
</span><span class="n">image</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">imread</span><span class="p">(</span><span class="sh">'</span><span class="s">noisy_image.jpg</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># Apply a median filter with a 5x5 kernel
</span><span class="n">median_filtered_image</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">medianBlur</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>

<span class="c1"># Apply a bilateral filter
</span><span class="n">bilateral_filtered_image</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">bilateralFilter</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">75</span><span class="p">,</span> <span class="mi">75</span><span class="p">)</span>

<span class="c1"># Display the original and filtered images
</span><span class="n">cv2</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="sh">'</span><span class="s">Original Image</span><span class="sh">'</span><span class="p">,</span> <span class="n">image</span><span class="p">)</span>
<span class="n">cv2</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="sh">'</span><span class="s">Median Filtered Image</span><span class="sh">'</span><span class="p">,</span> <span class="n">median_filtered_image</span><span class="p">)</span>
<span class="n">cv2</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="sh">'</span><span class="s">Bilateral Filtered Image</span><span class="sh">'</span><span class="p">,</span> <span class="n">bilateral_filtered_image</span><span class="p">)</span>

<span class="n">cv2</span><span class="p">.</span><span class="nf">waitKey</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">cv2</span><span class="p">.</span><span class="nf">destroyAllWindows</span><span class="p">()</span>
</code></pre></div></div>

<h2 id="54-keypoints">5.4 Keypoints</h2>

<ul>
  <li><strong>Non-linear filters</strong> are essential tools in image processing and computer vision, offering advantages over linear filters in terms of edge preservation, noise reduction, and handling complex image characteristics.</li>
  <li><strong>Common non-linear filters</strong> include median filters, bilateral filters, and adaptive filters, each serving specific purposes such as edge preservation, noise reduction, and morphological processing.</li>
  <li><strong>Application</strong>: Non-linear filters are widely used in tasks such as denoising, edge detection, image smoothing, and texture analysis, making them crucial in developing robust computer vision systems.</li>
</ul>
</section>
            </div><div class="search-results">
    <div class="has-results">
        <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
        <ul class="search-results-list"></ul>
    </div>
    <div class="no-results">
        <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
    </div>
</div></div>
    </div>
</div>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.7.1/jquery.min.js"></script>

<!-- introduce js_includes_ex support -->

<script>

    // Libraries to add dynamic tags below using .html files
    
    
    window.sciptsLib = new Map();
    window.cssLib = new Map();
    window.scipts = new Map();
    window.links = new Map();
    var jsIdIdx = 0;
    var cssIdIdx = 0;
    
    window.sciptsLib.set('bootstrap', [
        {uri: '//cdn.jsdelivr.net/npm/popper.js@1.12.9/dist/umd/popper.min.js'},
        {uri: '//cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js'}
    ]);
    window.cssLib.set('bootstrap', {uri: '//cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css'});
    
    window.sciptsLib.set('prism', {uri: '/ds/aml/assets/libs/prism/prism.js', defer: false});
    window.cssLib.set('prism', {uri: '/ds/aml/assets/libs/prism/prism.css', defer: false});

    //window.sciptsLib.set('xmind', {uri: '/ds/aml/assets/xmind/umd/xmind-embed-viewer.js', defer: false});
    
    // animate is included in head.html to support logo animation in navbar
    // window.cssLib.set('animate', {uri: '//cdnjs.cloudflare.com/ajax/libs/animate.css/4.1.1/animate.min.css'});
    
    // Add the script tags before the following element
    var getbookStyleElement = document.getElementById("gitbook_style")

    // Adding script tags to externally link js
        keyName = `prism_js`

        if (!window.scipts.get(keyName)) {

            // Get the links from sciptsLib
            jsLinks = window.sciptsLib.get( 'prism');

            if (jsLinks instanceof Array) {
            
                let scriptTags = []            
                
                for (i in jsLinks) {
                    scriptTag = document.createElement("script")
                    scriptTag.src = jsLinks[i]['uri'];                    
                    scriptTag.defer = ('defer' in jsLinks[i]) ? jsLinks[i]['defer'] : true;
                    scriptTag.id =  `prism_js_${jsIdIdx++}`;
                    document.head.insertBefore(scriptTag, getbookStyleElement)
                    
                    scriptTags.push(scriptTag);
                    console.log(scriptTag)
                }

                // Add script tags to window.scripts map object
                window.scipts.set(keyName, scriptTags)
            
            } else if (window.sciptsLib.has( 'prism')) {

                scriptTag = document.createElement("script");
                // console.log("sadasd", prism, jsLinks);
                scriptTag.src = jsLinks['uri'];
                scriptTag.defer = ('defer' in jsLinks) ? jsLinks['defer'] : true;
                scriptTag.id =  `prism_js_${jsIdIdx++}`;
                document.head.insertBefore(scriptTag, getbookStyleElement)
                console.log(scriptTag)

                // Add script tag to window.scripts map object
                window.scipts.set(keyName, scriptTag);
            }
        }


        // Adding link tags to externally link css
        keyName = `prism_css`

        if (!window.scipts.get(keyName)) {

            // Get the links from cssLib
            cssLinks = window.cssLib.get( 'prism');            
            
            if (cssLinks instanceof Array) {
            
                let cssLinkTags = []            
                
                for (i in cssLinks) {
                    cssLinkTag = document.createElement("script")
                    cssLinkTag.href = cssLinks[i]['uri'];
                    cssLinkTag.defer = ('defer' in cssLinks[i]) ? cssLinks[i]['defer'] : true;
                    cssLinkTag.id =  `prism_css_${cssIdIdx++}`;
                    cssLinkTag.rel = 'stylesheet';
                    document.head.insertBefore(cssLinkTag, getbookStyleElement)
                    
                    cssLinkTags.push(cssLinkTag);
                    console.log(cssLinkTag)
                }

                // Add script tags to window.scripts map object
                window.scipts.set(keyName, cssLinkTags)
            
            } else if (window.cssLib.has( 'prism')) {

                cssLinkTag = document.createElement("link")
                cssLinkTag.href = cssLinks['uri'];
                cssLinkTag.defer = ('defer' in cssLinks) ? cssLinks['defer'] : true;
                cssLinkTag.id =  `prism_css_${cssIdIdx++}`;
                cssLinkTag.rel = 'stylesheet';
                document.head.insertBefore(cssLinkTag, getbookStyleElement)

                console.log(cssLinkTag)

                // Add script tag to window.scripts map object
                window.scipts.set(keyName, cssLinkTag);
            }
        }    
        
    // Adding script tags to externally link js
        keyName = `mathjax_js`

        if (!window.scipts.get(keyName)) {

            // Get the links from sciptsLib
            jsLinks = window.sciptsLib.get( 'mathjax');

            if (jsLinks instanceof Array) {
            
                let scriptTags = []            
                
                for (i in jsLinks) {
                    scriptTag = document.createElement("script")
                    scriptTag.src = jsLinks[i]['uri'];                    
                    scriptTag.defer = ('defer' in jsLinks[i]) ? jsLinks[i]['defer'] : true;
                    scriptTag.id =  `mathjax_js_${jsIdIdx++}`;
                    document.head.insertBefore(scriptTag, getbookStyleElement)
                    
                    scriptTags.push(scriptTag);
                    console.log(scriptTag)
                }

                // Add script tags to window.scripts map object
                window.scipts.set(keyName, scriptTags)
            
            } else if (window.sciptsLib.has( 'mathjax')) {

                scriptTag = document.createElement("script");
                // console.log("sadasd", mathjax, jsLinks);
                scriptTag.src = jsLinks['uri'];
                scriptTag.defer = ('defer' in jsLinks) ? jsLinks['defer'] : true;
                scriptTag.id =  `mathjax_js_${jsIdIdx++}`;
                document.head.insertBefore(scriptTag, getbookStyleElement)
                console.log(scriptTag)

                // Add script tag to window.scripts map object
                window.scipts.set(keyName, scriptTag);
            }
        }


        // Adding link tags to externally link css
        keyName = `mathjax_css`

        if (!window.scipts.get(keyName)) {

            // Get the links from cssLib
            cssLinks = window.cssLib.get( 'mathjax');            
            
            if (cssLinks instanceof Array) {
            
                let cssLinkTags = []            
                
                for (i in cssLinks) {
                    cssLinkTag = document.createElement("script")
                    cssLinkTag.href = cssLinks[i]['uri'];
                    cssLinkTag.defer = ('defer' in cssLinks[i]) ? cssLinks[i]['defer'] : true;
                    cssLinkTag.id =  `mathjax_css_${cssIdIdx++}`;
                    cssLinkTag.rel = 'stylesheet';
                    document.head.insertBefore(cssLinkTag, getbookStyleElement)
                    
                    cssLinkTags.push(cssLinkTag);
                    console.log(cssLinkTag)
                }

                // Add script tags to window.scripts map object
                window.scipts.set(keyName, cssLinkTags)
            
            } else if (window.cssLib.has( 'mathjax')) {

                cssLinkTag = document.createElement("link")
                cssLinkTag.href = cssLinks['uri'];
                cssLinkTag.defer = ('defer' in cssLinks) ? cssLinks['defer'] : true;
                cssLinkTag.id =  `mathjax_css_${cssIdIdx++}`;
                cssLinkTag.rel = 'stylesheet';
                document.head.insertBefore(cssLinkTag, getbookStyleElement)

                console.log(cssLinkTag)

                // Add script tag to window.scripts map object
                window.scipts.set(keyName, cssLinkTag);
            }
        }    
        
    

</script>



<script>
window.MathJax = {
  tex: {
    inlineMath: [ ['$', '$'], ['\\(', '\\)'] ]
  },
  svg: {
    fontCache: 'global'
  }
};
</script>
<script
  type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
</script>





<!-- introduce mathjax support -->
<script>
    function fixes_chrome_anchors() {
        let chrome = /Chrome/.test(navigator.userAgent) && /Google Inc/.test(navigator.vendor);
        if (window.location.hash && chrome) {
            setTimeout(function () {
                var hash = window.location.hash;
                window.location.hash = "";
                window.location.hash = hash;
            }, 300);
        }
    }

    if (document.readyState === "loading") {
        // Loading hasn't finished yet
        document.addEventListener("DOMContentLoaded", fixes_chrome_anchors);
    } else {
        // `DOMContentLoaded` has already fired
        fixes_chrome_anchors();
    }
</script>


                        <a href="/ds/aml/basics/1_ima_1_basics/" class="navigation navigation-prev navigation-unique hide_element" aria-label="Previous page: 1. Introduction"> <!-- class="hide_element" -->
                            <i class="fa fa-angle-left"></i>
                        </a>
                    

                    
                        <a href="/ds/aml/image_analysis/1_ima_3_edge_detectors/" class="navigation navigation-next navigation-unique" aria-label="Next page: 3. Edge Detectors"> <!-- class="hide_element" -->
                            <i class="fa fa-angle-right"></i>
                        </a>
                    
                    <div class="copyright"><span>&copy; 2024 Intelligent Mind Labs, Inc. All rights reserved.</span>.</div>
                </div>
            </div>

            <script>
                // div "book" element's content is the only content refreshed when nav link is pressed.
                // This functionality is implemented in "gitbook.js" and "theme.js"
                // head.html and footer.html will not be called again and again when a new nav link is clicked
                // Gitbook js is optimized to dynamically change content inside div "book" element.
                // Due to this: script put in the footer will only be called once,
                // which is the very first time the page is loaded by entering
                // the web address in the address bar in the browser
                // 
                $ = jQuery;
                $(function() {
                    // spinnerHide();
                    // setTimeout(spinnerHide, 200);
           
                    $('.childBtn').on('click', function(event) {
                        event.stopImmediatePropagation(); // To prevent following the link (optional)
                        window.location = $(this).attr('link');
                    });

                    $('.parentBtn').on('click', function(event) {
                        window.location = $(this).attr('link');
                    });
                });
            </script>

            <script>
            var gitbook = gitbook || [];
            gitbook.push(function() {
                gitbook.page.hasChanged({
    "page": {
        "title": "Introduction",
        "level": "1.1",
        "depth": 1,
        
        "next": {
            "title": "3. Edge Detectors",
            "level": "1.2",
            "depth": 1,
            "path": "_4_problem_domains/1_ima_3_edge_detectors.md",
            "ref": "_4_problem_domains/1_ima_3_edge_detectors.md",
            "articles": []
        },
        
        "dir": "ltr"
    },    "config": {
        "plugins": ["fontsettings", "highlight", "livereload", "lunr", "search", "sharing", "theme-default", "livereload"],
        "styles": {
            "ebook": "styles/ebook.css",
            "epub": "styles/epub.css",
            "mobi": "styles/mobi.css",
            "pdf": "styles/pdf.css",
            "print": "styles/print.css",
            "website": "styles/website.css"
        },
        "pluginsConfig": {
            "expandable-chapter-small2": {
                "articlesExpand": true,
            },
            "fontsettings": {
                "family": "sans",
                "size": 2,
                "theme": "white"
            },
            "highlight": {},
            "livereload": {},
            "lunr": {
                "ignoreSpecialCharacters": false,
                "maxIndexSize": 1000000
            },
            "search": {},            "sharing": {
                "facebook": true,

                "google": false,

                "github": true,
              
                "github_link": "https://github.com",
              

                "telegram": false,
                "telegram_link": "https://t.me",

                "instapaper": false,

                "twitter": true,
              

                "vk": false,

                "weibo": false,

                "all": ["facebook", "google", "twitter", "weibo", "instapaper", "github", "telegram"]
            },
"theme-default": {
                "showLevel": false,
                "styles": {
                    "ebook": "styles/ebook.css",
                    "epub": "styles/epub.css",
                    "mobi": "styles/mobi.css",
                    "pdf": "styles/pdf.css",
                    "print": "styles/print.css",
                    "website": "styles/website.css"
                }
            },
        },
        "theme": "default",
        "author": "Intelligent Mind Labs",
        "pdf": {
            "pageNumbers": true,
            "fontSize": 12,
            "fontFamily": "Arial",
            "paperSize": "a4",
            "chapterMark": "pagebreak",
            "pageBreaksBefore": "/",
            "margin": {
                "right": 62,
                "left": 62,
                "top": 56,
                "bottom": 56
            }
        },
        "structure": {
            "langs": "LANGS.md",
            "readme": "README.md",
        },
        "variables": {},
        "title": "Wiki | Advance Machine Learning",
        "language": "en",
        "gitbook": "*"
    },
    "file": {
        "path": "_4_problem_domains/1_ima_2_filters.md",
        "mtime": "2019-04-27 00:00:00 +0800",
        "type": "markdown"
    },
    "gitbook": {
        "version": "3.2.3",
        "time": "2024-08-13 14:28:11 +0800"
    },
    "basePath": "/ds/aml",
    "book": {
        "language": ""
    }
});
            });

            </script>
        </div><script src="/ds/aml/assets/gitbook/gitbook.js"></script>
<script src="/ds/aml/assets/gitbook/theme.js"></script>

<script src="/ds/aml/assets/gitbook/gitbook-plugin-back-to-top-button/plugin.js" async=""></script>
<!-- <script src="/ds/aml/assets/gitbook/gitbook-plugin-copy-code-button/toggle.js"></script> -->
<script src="/ds/aml/assets/gitbook/gitbook-plugin-expandable-chapters-small2/expandable-chapters-small.js"></script>
<script src="/ds/aml/assets/gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
<script src="/ds/aml/assets/gitbook/gitbook-plugin-search-pro/jquery.mark.min.js" defer=""></script>
<script src="/ds/aml/assets/gitbook/gitbook-plugin-search-pro/search.js" defer=""></script>
<script src="/ds/aml/assets/gitbook/gitbook-plugin-sharing/buttons.js" defer=""></script>
<script src="/ds/aml/assets/gitbook/gitbook-plugin-splitter/splitter.js" defer=""></script>




<!--
<script src="../gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
<script src="../gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
<script src="../gitbook/gitbook-plugin-search/search-engine.js"></script>
<script src="../gitbook/gitbook-plugin-search/search.js"></script>
-->



<script>
function spinnerHide() {
    $(".spinner-container").removeClass("show_element");
    $(".spinner-container").addClass("hide_element");
    $(".spinner-container").addClass("display_none");
    

    $("#book-search-results").removeClass("hide_element");
    $("#book-search-results").addClass("show_element");

    $(".navigation.navigation-next").removeClass("hide_element");
    $(".navigation.navigation-next").addClass("show_element");

    $(".navigation.navigation-prev").removeClass("hide_element");
    $(".navigation.navigation-prev").addClass("show_element");
}        
</script><!-- trackers --><!-- google analytics --><!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-V3WBTFTQWG"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-V3WBTFTQWG');
</script>
</body>
</html>