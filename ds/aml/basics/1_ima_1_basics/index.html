<!DOCTYPE HTML>
<html lang="en" >
    <head><meta charset="UTF-8">
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"><title>1. Introduction · Intelligent Mind Labs</title><meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="description" content="Wikis for Data Science, Computing, Software Development, Math, etc.
"><!-- <meta name="generator" content="Jekyll (using style of GitBook 3.2.3)"> --><meta name="author" content="Intelligent Mind Labs"><!-- <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script> -->
<!-- <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.7.1/jquery.min.js"></script> -->

<!-- For logo animation -->
<!-- <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/animate.css/4.1.1/animate.min.css"> -->

<link rel="stylesheet" href="/ds/aml/assets/fonts/fa5.15/css/all.min.css">

<link id="gitbook_style" rel="stylesheet" href="/ds/aml/assets/gitbook/style.css">
<link rel="stylesheet" href="/ds/aml/assets/gitbook/gitbook-plugin-back-to-top-button/plugin.css">
<link rel="stylesheet" href="/ds/aml/assets/gitbook/gitbook-plugin-expandable-chapters-small2/expandable-chapters-small.css">
<link rel="stylesheet" href="/ds/aml/assets/gitbook/gitbook-plugin-fontsettings/website.css">
<link rel="stylesheet" href="/ds/aml/assets/gitbook/gitbook-plugin-search-pro/search.css">
<link rel="stylesheet" href="/ds/aml/assets/gitbook/gitbook-plugin-splitter/splitter.css">



<!-- <link rel="stylesheet" href="/ds/aml/assets/gitbook/rouge/colorful.css"> -->

<style>
@import url('https://fonts.googleapis.com/css2?family=Exo:ital,wght@0,100..900;1,100..900&display=swap');
</style>
    

<link rel="stylesheet" href="/ds/aml/assets/gitbook/custom.css">
<link rel="stylesheet" href="/ds/aml/assets/gitbook/custom-local.css"><style>
.img_url {
    content: url("/ds/aml/assets/images/wiki.imindlabs.grey.logo.png");
}

.book.color-theme-2 .img_url {
    content: url("/ds/aml/assets/images/wiki.imindlabs.logo.png");
}
</style><link rel="stylesheet" href="/ds/aml/assets/gitbook/custom-local-child.css">

<meta name="HandheldFriendly" content="true"/>
<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black">
<!-- <link rel="apple-touch-icon-precomposed" sizes="152x152" href="/ds/aml/assets/gitbook/images/apple-touch-icon-precomposed-152.png"> -->
<!-- <link rel="shortcut icon" href="/ds/aml/wiki.imindlabs.favicon.png" type="image/x-icon"> -->
<link rel="apple-touch-icon-precomposed" sizes="152x152" href="/ds/aml/wiki.imindlabs.favicon.png">
<link rel="icon" href="/ds/aml/wiki.imindlabs.favicon.png" sizes="32x32" type="image/png">
<link rel="icon" href="/ds/aml/wiki.imindlabs.favicon.png" sizes="16x16" type="image/png">
<link rel="shortcut icon" href="/ds/aml/wiki.imindlabs.favicon.png" type="image/png">



<!-- trackers -->
            <link rel="prev" href="/ds/aml/" />
        

        
            <link rel="next" href="/ds/aml/image_analysis/1_ima_2_filters/" />
        
    </head>
    <body>         
        <div class="book"><div class="book-summary">
    <script type="text/javascript">
        // Fixes the page links scroll problem on both desktop and mobile browsers
        function pageScrollToTop(element) {
            // both mobile and non-mobile
            $('div.body-inner').animate({ scrollTop: 0 });
            $(element).parent().find('li>ul>li').removeClass('active');
            return true;  // propagate
        }
        // Fixes the anchor links scroll problem on mobile browsers
        function mobilePageScrollToAnchor(element) {
            $(element).closest('li.chapter').find('ul>li').removeClass('active');
            $(element).parent().addClass('active');
            
            // ! BUG: Enable the following functionality on large screen sizes
            // On sub menu item click the page did not navigate. Now it does.
            //if ($(document).width() <= 1240) {
                $('div.body-inner').animate({ scrollTop: $($(element).attr('href')).get(0).offsetTop });
            // }
            return true;
        }
    </script>

    <!-- <div style="text-align:center;" class="animate__animated animate__pulse animate__delay-1s">
        <a href="/ds/aml/">
            <img class="logo zoom" src="/ds/aml/assets/images/wiki.imindlabs.logo.png" alt="Intelligent Mind Labs wiki logo" />
        </a>
    </div> -->
    <div style="text-align:center;" class="logo-wrap">
        <a href="/ds/aml/">
            <img class="logo zoom" src="/ds/aml/assets/images/wiki.imindlabs.logo_153x200.webp" alt="Intelligent Mind Labs wiki logo" width="153" height="200"/>
        </a>
    </div>

    <nav role="navigation">
        <div id="book-search-input" role="search">
            <input type="text" placeholder="Type to search" />
        </div>
        <div id="book-search-input-link" role="search">
            <a href="/ds/aml/assets/search.html">Click to Search</a>
        </div>
        <ul class="summary">
            
            <li class="chapter" data-level="1.1" data-path="/ds/aml">
                
                <a href="/ds/aml/" onclick="pageScrollToTop(this)">
                    Wiki | Advance Machine Learning
                </a>
            </li>

            <!-- <li class="divider"></li> -->

            
            <!-- <p>1_learning_domains</p> -->
            
                <p class="collection-title">Learning Domains</p>
            
            
            

            

            
            
            
            <!-- <p>2_dataset_preparation</p> -->
            
                <p class="collection-title">Dataset Preparation</p>
            
            
            

            

            
            
            
            <!-- <p>3_feature_analysis</p> -->
            
                <p class="collection-title">Feature Analysis</p>
            
            
            

            

            
            
            
            <!-- <p>4_problem_domains</p> -->
            
                <p class="collection-title">Problem Domains</p>
            
            
            

            
            
            
            <p class="separator-title">Image Processing</p>
            
            
            
            <li class="chapter active" data-level="1.2" data-path="/ds/aml/basics/1_ima_1_basics/">
                
                <a href="/ds/aml/basics/1_ima_1_basics/" onclick="pageScrollToTop(this)">
                    1. Introduction
                </a>
                
                
                <ul><li><a href="#1-color-conversions" onclick="mobilePageScrollToAnchor(this)" >1. Color Conversions</a><ul><li><a href="#11-common-color-conversions-in-opencv" onclick="mobilePageScrollToAnchor(this)" >1.1 Common Color Conversions in OpenCV</a></li><li><a href="#12-impact-of-color-conversions-on-machine-learning-tasks-in-computer-vision" onclick="mobilePageScrollToAnchor(this)" >1.2 Impact of Color Conversions on Machine Learning Tasks in Computer Vision</a></li><li><a href="#example" onclick="mobilePageScrollToAnchor(this)" >Example</a></li><li><a href="#13-keypoints" onclick="mobilePageScrollToAnchor(this)" >1.3 Keypoints</a></li></ul></li><li><a href="#2-pixel-transformation" onclick="mobilePageScrollToAnchor(this)" >2. Pixel Transformation</a><ul><li><a href="#21-common-pixel-transform-techniques" onclick="mobilePageScrollToAnchor(this)" >2.1 Common Pixel Transform Techniques</a></li><li><a href="#22-applications-in-computer-vision" onclick="mobilePageScrollToAnchor(this)" >2.2 Applications in Computer Vision</a></li><li><a href="#23-example" onclick="mobilePageScrollToAnchor(this)" >2.3 Example</a></li><li><a href="#24-keypoints" onclick="mobilePageScrollToAnchor(this)" >2.4 Keypoints</a></li></ul></li><li><a href="#3-histogram-equalization" onclick="mobilePageScrollToAnchor(this)" >3. Histogram Equalization</a><ul><li><a href="#31-how-it-works" onclick="mobilePageScrollToAnchor(this)" >3.1 How It Works</a></li><li><a href="#32-example" onclick="mobilePageScrollToAnchor(this)" >3.2 Example</a></li><li><a href="#33-histogram-equalization-in-opencv" onclick="mobilePageScrollToAnchor(this)" >3.3 Histogram Equalization in OpenCV</a></li><li><a href="#34--keypoints" onclick="mobilePageScrollToAnchor(this)" >3.4  Keypoints</a></li></ul></li><li><a href="#4-histogram-equalization-vs-matching" onclick="mobilePageScrollToAnchor(this)" >4. Histogram Equalization vs Matching</a><ul><li><a href="#41-histogram-equalization" onclick="mobilePageScrollToAnchor(this)" >4.1 Histogram Equalization</a></li><li><a href="#42-histogram-matching-histogram-specification" onclick="mobilePageScrollToAnchor(this)" >4.2 Histogram Matching (Histogram Specification)</a></li><li><a href="#43-differences-between-histogram-equalization-and-histogram-matching" onclick="mobilePageScrollToAnchor(this)" >4.3 Differences Between Histogram Equalization and Histogram Matching</a></li><li><a href="#44-importance-in-computer-vision" onclick="mobilePageScrollToAnchor(this)" >4.4 Importance in Computer Vision</a></li><li><a href="#45-example" onclick="mobilePageScrollToAnchor(this)" >4.5 Example</a></li><li><a href="#46-keypoints" onclick="mobilePageScrollToAnchor(this)" >4.6 Keypoints</a></li></ul></li><li><a href="#5-morphology-operators" onclick="mobilePageScrollToAnchor(this)" >5. Morphology Operators</a><ul><li><a href="#51-key-morphological-operators" onclick="mobilePageScrollToAnchor(this)" >5.1 Key Morphological Operators</a></li><li><a href="#52-importance-in-computer-vision" onclick="mobilePageScrollToAnchor(this)" >5.2 Importance in Computer Vision</a></li><li><a href="#53-example" onclick="mobilePageScrollToAnchor(this)" >5.3 Example</a></li><li><a href="#54-keypoints" onclick="mobilePageScrollToAnchor(this)" >5.4 Keypoints</a></li></ul></li></ul>

                
                
            </li>
            
            
            
            
            
            <li class="chapter" data-level="1.1" data-path="/ds/aml/image_analysis/1_ima_2_filters/">
                
                <a href="/ds/aml/image_analysis/1_ima_2_filters/" onclick="pageScrollToTop(this)">
                    2. Filters
                </a>
                
                
                
            </li>
            
            
            
            
            
            <li class="chapter" data-level="1.1" data-path="/ds/aml/image_analysis/1_ima_3_edge_detectors/">
                
                <a href="/ds/aml/image_analysis/1_ima_3_edge_detectors/" onclick="pageScrollToTop(this)">
                    3. Edge Detectors
                </a>
                
                
                
            </li>
            
            
            
            
            
            <li class="chapter" data-level="1.1" data-path="/ds/aml/image_analysis/1_ima_4_corner_detectors/">
                
                <a href="/ds/aml/image_analysis/1_ima_4_corner_detectors/" onclick="pageScrollToTop(this)">
                    4. Corner Detectors
                </a>
                
                
                
            </li>
            
            
            
            
            
            <li class="chapter" data-level="1.1" data-path="/ds/aml/image_analysis/1_ima_5_region_detectors/">
                
                <a href="/ds/aml/image_analysis/1_ima_5_region_detectors/" onclick="pageScrollToTop(this)">
                    5. Region Detectors
                </a>
                
                
                
            </li>
            
            
            
            
            
            <li class="chapter" data-level="1.1" data-path="/ds/aml/image_analysis/1_ima_6_keypoints/">
                
                <a href="/ds/aml/image_analysis/1_ima_6_keypoints/" onclick="pageScrollToTop(this)">
                    6. Keypoint Detectors
                </a>
                
                
                
            </li>
            
            
            
            <p class="separator-title">Regression</p>
            
            
            
            <li class="chapter" data-level="1.1" data-path="/ds/aml/basics/1_regression_1_cv/">
                
                <a href="/ds/aml/basics/1_regression_1_cv/" onclick="pageScrollToTop(this)">
                    1. Computer Vision
                </a>
                
                
                
            </li>
            
            
            
            
            
            <li class="chapter" data-level="1.1" data-path="/ds/aml/basics/1_regression_1_nlp/">
                
                <a href="/ds/aml/basics/1_regression_1_nlp/" onclick="pageScrollToTop(this)">
                    2. Natural Language Processing
                </a>
                
                
                
            </li>
            

            
            <!-- <li class="divider"></li> -->
            
            
            
            <!-- <p>posts</p> -->
            
            
            

            

            
            
            
        </ul>
    </nav>
</div><div class="book-body">
                <div class="book-header" role="navigation">
                    <!-- Title -->
                    <h1>
                        <i class="fa fa-circle-o-notch fa-spin"></i>
                        
                            <a href="." >1. Introduction</a>
                        
                    </h1>
                </div>

                <div class="body-inner"><div class="page-wrapper" tabindex="-1" role="main">
    

    <!-- <div class="spinner-container">
        <div class="spinner-border text-info" role="status">
            <span class="visually-hidden">Loading...</span>
        </div>
    </div> -->

    <div class="page-inner">
        <div id="book-search-results"> <!-- class="hide_element" -->            
            <div class="search-noresults">
                <section class="normal markdown-section">
                    
                        <h1 id="/basics/1_ima_1_basics">1. Introduction</h1>
                    

                    <h1 id="1-color-conversions">1. Color Conversions</h1>

<p>OpenCV offers a wide range of color conversions that are critical for various image processing and computer vision tasks. These conversions allow for the manipulation of images in different color spaces, which can significantly affect the performance of machine learning models in computer vision.</p>

<h2 id="11-common-color-conversions-in-opencv">1.1 Common Color Conversions in OpenCV</h2>

<p><strong>1. BGR to Grayscale (<code class="language-plaintext highlighter-rouge">cv2.COLOR_BGR2GRAY</code>)</strong>:</p>
<ul>
  <li>Converts an image from Blue-Green-Red (BGR) color space (which is the default color space in OpenCV) to Grayscale.</li>
  <li><strong>Effect on Machine Learning</strong>: Grayscale images reduce the dimensionality of the input data by eliminating color information, often used in tasks where color is not essential, like edge detection or certain texture analyses.</li>
</ul>

<p><strong>2. BGR to RGB (<code class="language-plaintext highlighter-rouge">cv2.COLOR_BGR2RGB</code>)</strong>:</p>
<ul>
  <li>Converts an image from BGR to RGB color space.</li>
  <li><strong>Effect on Machine Learning</strong>: RGB is the standard color space for most image datasets and visualization libraries. Converting to RGB ensures consistency when working with pre-trained models or datasets.</li>
</ul>

<p><strong>3. BGR to HSV (<code class="language-plaintext highlighter-rouge">cv2.COLOR_BGR2HSV</code>)</strong>:</p>
<ul>
  <li>Converts an image from BGR to Hue-Saturation-Value (HSV) color space.</li>
  <li><strong>Effect on Machine Learning</strong>: HSV separates chromatic content (color) from intensity, making it useful for tasks involving color segmentation, detection, and tracking, where color information is more important than intensity.</li>
</ul>

<p><strong>4. BGR to LAB (<code class="language-plaintext highlighter-rouge">cv2.COLOR_BGR2LAB</code>)</strong>:</p>
<ul>
  <li>Converts an image from BGR to CIELAB color space, which is designed to be perceptually uniform.</li>
  <li><strong>Effect on Machine Learning</strong>: LAB is useful for color-based tasks where perceptual differences in color need to be emphasized, such as color-based clustering or color constancy.</li>
</ul>

<p><strong>5. BGR to YCrCb (<code class="language-plaintext highlighter-rouge">cv2.COLOR_BGR2YCrCb</code>)</strong>:</p>
<ul>
  <li>Converts an image from BGR to YCrCb color space, where Y is the luminance, and Cr, Cb are the chrominance components.</li>
  <li><strong>Effect on Machine Learning</strong>: YCrCb is often used in compression and face detection tasks, as it separates the intensity from color information, making it easier to work with luminance variations.</li>
</ul>

<p><strong>6. BGR to HLS (<code class="language-plaintext highlighter-rouge">cv2.COLOR_BGR2HLS</code>)</strong>:</p>
<ul>
  <li>Converts an image from BGR to Hue-Lightness-Saturation (HLS) color space.</li>
  <li><strong>Effect on Machine Learning</strong>: HLS is similar to HSV but emphasizes lightness, which can be beneficial in tasks involving brightness-based segmentation or analysis.</li>
</ul>

<p><strong>7. BGR to XYZ (<code class="language-plaintext highlighter-rouge">cv2.COLOR_BGR2XYZ</code>)</strong>:</p>
<ul>
  <li>Converts an image from BGR to the CIE 1931 XYZ color space, which represents colors based on human vision.</li>
  <li><strong>Effect on Machine Learning</strong>: XYZ is used in color matching and color correction tasks, particularly when aligning images from different devices.</li>
</ul>

<p><strong>8. Grayscale to BGR (<code class="language-plaintext highlighter-rouge">cv2.COLOR_GRAY2BGR</code>)</strong>:</p>
<ul>
  <li>Converts a grayscale image back to BGR.</li>
  <li><strong>Effect on Machine Learning</strong>: This is useful when a model expects a 3-channel input, but the source image is grayscale.</li>
</ul>

<h2 id="12-impact-of-color-conversions-on-machine-learning-tasks-in-computer-vision">1.2 Impact of Color Conversions on Machine Learning Tasks in Computer Vision</h2>

<p><strong>1. Feature Extraction</strong>:</p>
<ul>
  <li>Different color spaces can highlight different aspects of an image, influencing feature extraction. For example, HSV can make it easier to detect objects based on color, while LAB can enhance perceptual color differences.</li>
</ul>

<p><strong>2. Dimensionality Reduction</strong>:</p>
<ul>
  <li>Converting to grayscale reduces the image’s dimensionality, which can simplify models and reduce computation costs. However, it also discards color information, which might be critical for certain tasks.</li>
</ul>

<p><strong>3. Preprocessing</strong>:</p>
<ul>
  <li>Certain models, especially those trained on specific color spaces (like RGB), require images to be converted to that space during preprocessing. Failing to do so can result in poor model performance.</li>
</ul>

<p><strong>4. Segmentation</strong>:</p>
<ul>
  <li>Color-based segmentation often relies on conversions to color spaces like HSV or LAB, where color components are more easily separated from intensity, leading to more effective segmentation.</li>
</ul>

<p><strong>5. Normalization</strong>:</p>
<ul>
  <li>Some color spaces like LAB and YCrCb are used to normalize images in a way that is consistent with human perception, which can improve the robustness of models against lighting variations.</li>
</ul>

<p><strong>6. Data Augmentation</strong>:</p>
<ul>
  <li>Color space transformations can be used as a form of data augmentation, providing models with a more diverse set of inputs and improving generalization.</li>
</ul>

<h2 id="example">Example</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">cv2</span>

<span class="c1"># Load an image
</span><span class="n">image</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">imread</span><span class="p">(</span><span class="sh">'</span><span class="s">image.jpg</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># Convert BGR to RGB
</span><span class="n">image_rgb</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">cvtColor</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">COLOR_BGR2RGB</span><span class="p">)</span>

<span class="c1"># Convert BGR to Grayscale
</span><span class="n">image_gray</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">cvtColor</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">COLOR_BGR2GRAY</span><span class="p">)</span>

<span class="c1"># Convert BGR to HSV
</span><span class="n">image_hsv</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">cvtColor</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">COLOR_BGR2HSV</span><span class="p">)</span>

<span class="c1"># Display the images
</span><span class="n">cv2</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="sh">'</span><span class="s">Original</span><span class="sh">'</span><span class="p">,</span> <span class="n">image</span><span class="p">)</span>
<span class="n">cv2</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="sh">'</span><span class="s">RGB</span><span class="sh">'</span><span class="p">,</span> <span class="n">image_rgb</span><span class="p">)</span>
<span class="n">cv2</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="sh">'</span><span class="s">Grayscale</span><span class="sh">'</span><span class="p">,</span> <span class="n">image_gray</span><span class="p">)</span>
<span class="n">cv2</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="sh">'</span><span class="s">HSV</span><span class="sh">'</span><span class="p">,</span> <span class="n">image_hsv</span><span class="p">)</span>

<span class="n">cv2</span><span class="p">.</span><span class="nf">waitKey</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">cv2</span><span class="p">.</span><span class="nf">destroyAllWindows</span><span class="p">()</span>
</code></pre></div></div>

<h2 id="13-keypoints">1.3 Keypoints</h2>

<ul>
  <li><strong>Color conversions</strong> in OpenCV are essential tools in image preprocessing and feature extraction in machine learning tasks.</li>
  <li><strong>Different color spaces</strong> highlight different aspects of images, and the choice of color space can significantly affect the performance of computer vision algorithms.</li>
  <li><strong>Proper use of color conversions</strong> can lead to improved accuracy, robustness, and efficiency in tasks such as object detection, segmentation, and classification.</li>
</ul>

<h1 id="2-pixel-transformation">2. Pixel Transformation</h1>

<p>Pixel transform techniques in computer vision involve modifying the intensity or color values of individual pixels in an image based on a specific mathematical function or rule. These transformations are applied directly to the pixels without considering the spatial relationships between them, unlike convolutional filters or other spatial-domain operations. Pixel transforms are used for a variety of purposes, such as contrast enhancement, color correction, image normalization, and thresholding.</p>

<h2 id="21-common-pixel-transform-techniques">2.1 Common Pixel Transform Techniques</h2>

<p><strong>1. Linear Transformations</strong>:</p>
<ul>
  <li><strong>Operation</strong>: A simple linear transformation of pixel values using the equation \(I' = \alpha \cdot I + \beta\), where \(I\) is the original pixel intensity, \(\alpha\) is a scaling factor, and \(\beta\) is an offset.</li>
  <li><strong>Use Case</strong>: Used for brightness and contrast adjustment.</li>
  <li><strong>Example</strong>: Increasing contrast by scaling pixel values:
\(I' = 1.5 \cdot I - 50\)</li>
</ul>

<p><strong>2. Logarithmic and Exponential Transformations</strong>:</p>
<ul>
  <li><strong>Log Transform</strong>: \(I' = c \cdot \log(1 + I)\), where \(c\) is a constant.</li>
  <li><strong>Exponential Transform</strong>: \(I' = c \cdot (e^{kI} - 1)\), where \(c\) and \(k\) are constants.</li>
  <li><strong>Use Case</strong>: Used for dynamic range compression, where high-intensity values are reduced, and low-intensity values are enhanced.</li>
  <li><strong>Example</strong>: Enhancing details in a dark image using a log transform.</li>
</ul>

<p><strong>3. Gamma Correction</strong>:</p>
<ul>
  <li><strong>Operation</strong>: Adjusts the brightness of an image using the formula \(I' = I^\gamma\), where \(\gamma\) is a parameter that controls the transformation.</li>
  <li><strong>Use Case</strong>: Used to correct the brightness of images displayed on screens, where the relationship between input intensity and displayed brightness is non-linear.</li>
  <li><strong>Example</strong>: Brightening an image by using \(\gamma &lt; 1\).</li>
</ul>

<p><strong>4. Thresholding</strong>:</p>
<ul>
  <li><strong>Global Thresholding</strong>: Converts a grayscale image to binary by applying a single threshold value. Pixels above the threshold are set to one value (e.g., 255), and those below are set to another (e.g., 0).</li>
  <li><strong>Adaptive Thresholding</strong>: The threshold value is computed for smaller regions, adapting to local image characteristics.</li>
  <li><strong>Use Case</strong>: Common in segmentation tasks, such as separating foreground from background.</li>
  <li><strong>Example</strong>: Converting an image to binary using a threshold value of 128.</li>
</ul>

<p><strong>5. Histogram Equalization</strong>:</p>
<ul>
  <li><strong>Operation</strong>: Redistributes the intensity values of an image so that the histogram of the output image is approximately flat. This enhances the contrast of the image, especially in areas with low contrast.</li>
  <li><strong>Use Case</strong>: Used in contrast enhancement, particularly in images with poor lighting conditions.</li>
  <li><strong>Example</strong>: Applying histogram equalization to an underexposed image to improve visibility.</li>
</ul>

<p><strong>6. Bitwise Operations</strong>:</p>
<ul>
  <li><strong>Operations</strong>: Pixel-wise logical operations such as AND, OR, XOR, and NOT.</li>
  <li><strong>Use Case</strong>: Used for masking, blending, and performing operations on binary images or performing logical operations between multiple images.</li>
  <li><strong>Example</strong>: Applying a mask to an image using a bitwise AND operation.</li>
</ul>

<p><strong>7. Inversion (Negative Transformation)</strong>:</p>
<ul>
  <li><strong>Operation</strong>: Inverts the intensity values of an image using the formula \(I' = 255 - I\) for an 8-bit grayscale image.</li>
  <li><strong>Use Case</strong>: Used to create negative images, useful in certain medical imaging applications like X-rays.</li>
  <li><strong>Example</strong>: Converting a bright image into its negative.</li>
</ul>

<p><strong>8. Color Space Transformations</strong>:</p>
<ul>
  <li><strong>Operation</strong>: Converts an image from one color space to another, such as from RGB to grayscale, HSV, or LAB.</li>
  <li><strong>Use Case</strong>: Used in tasks like color-based segmentation, feature extraction, and object recognition.</li>
  <li><strong>Example</strong>: Converting an RGB image to HSV to isolate specific colors for processing.</li>
</ul>

<p><strong>9. Intensity Scaling (Normalization)</strong>:</p>
<ul>
  <li><strong>Operation</strong>: Scales the pixel intensity values to a specific range, typically [0, 1] or [0, 255].</li>
  <li><strong>Use Case</strong>: Used to standardize images for comparison or processing, ensuring that the intensity values are consistent across different images.</li>
  <li><strong>Example</strong>: Normalizing pixel values to the range [0, 1] for input to a neural network.</li>
</ul>

<h2 id="22-applications-in-computer-vision">2.2 Applications in Computer Vision</h2>

<p><strong>1. Preprocessing</strong>:</p>
<ul>
  <li>Pixel transforms are commonly used as preprocessing steps in computer vision pipelines, helping to normalize, enhance, or correct images before further processing, such as in machine learning models.</li>
</ul>

<p><strong>2. Contrast and Brightness Adjustment</strong>:</p>
<ul>
  <li>Adjusting contrast and brightness using linear transformations or gamma correction is crucial for improving the visibility of features in an image, especially in low-light conditions.</li>
</ul>

<p><strong>3. Segmentation</strong>:</p>
<ul>
  <li>Thresholding is a fundamental technique for image segmentation, separating objects of interest from the background, which is a key step in many computer vision applications like object detection and recognition.</li>
</ul>

<p><strong>4. Color-Based Analysis</strong>:</p>
<ul>
  <li>Converting images to different color spaces (e.g., HSV or LAB) allows for more effective color-based feature extraction and segmentation, which is important in applications like traffic sign recognition and medical imaging.</li>
</ul>

<p><strong>5. Dynamic Range Compression</strong>:</p>
<ul>
  <li>Techniques like logarithmic transformations and histogram equalization are used to compress the dynamic range of images, making them more suitable for display on screens or for further analysis.</li>
</ul>

<h2 id="23-example">2.3 Example</h2>

<p>Here’s how you can apply some of these pixel transform techniques using OpenCV:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">cv2</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="c1"># Load a grayscale image
</span><span class="n">image</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">imread</span><span class="p">(</span><span class="sh">'</span><span class="s">image.jpg</span><span class="sh">'</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">IMREAD_GRAYSCALE</span><span class="p">)</span>

<span class="c1"># Apply gamma correction
</span><span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">gamma_corrected</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">power</span><span class="p">(</span><span class="n">image</span> <span class="o">/</span> <span class="mf">255.0</span><span class="p">,</span> <span class="n">gamma</span><span class="p">)</span> <span class="o">*</span> <span class="mf">255.0</span>
<span class="n">gamma_corrected</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">uint8</span><span class="p">(</span><span class="n">gamma_corrected</span><span class="p">)</span>

<span class="c1"># Apply histogram equalization
</span><span class="n">equalized_image</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">equalizeHist</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

<span class="c1"># Apply thresholding
</span><span class="n">_</span><span class="p">,</span> <span class="n">binary_image</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">threshold</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">THRESH_BINARY</span><span class="p">)</span>

<span class="c1"># Invert the image
</span><span class="n">inverted_image</span> <span class="o">=</span> <span class="mi">255</span> <span class="o">-</span> <span class="n">image</span>

<span class="c1"># Display the results
</span><span class="n">cv2</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="sh">'</span><span class="s">Original Image</span><span class="sh">'</span><span class="p">,</span> <span class="n">image</span><span class="p">)</span>
<span class="n">cv2</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="sh">'</span><span class="s">Gamma Corrected Image</span><span class="sh">'</span><span class="p">,</span> <span class="n">gamma_corrected</span><span class="p">)</span>
<span class="n">cv2</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="sh">'</span><span class="s">Histogram Equalized Image</span><span class="sh">'</span><span class="p">,</span> <span class="n">equalized_image</span><span class="p">)</span>
<span class="n">cv2</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="sh">'</span><span class="s">Binary Image</span><span class="sh">'</span><span class="p">,</span> <span class="n">binary_image</span><span class="p">)</span>
<span class="n">cv2</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="sh">'</span><span class="s">Inverted Image</span><span class="sh">'</span><span class="p">,</span> <span class="n">inverted_image</span><span class="p">)</span>

<span class="n">cv2</span><span class="p">.</span><span class="nf">waitKey</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">cv2</span><span class="p">.</span><span class="nf">destroyAllWindows</span><span class="p">()</span>
</code></pre></div></div>

<h2 id="24-keypoints">2.4 Keypoints</h2>

<ul>
  <li><strong>Pixel transform techniques</strong> modify the intensity or color of individual pixels based on specific rules, without considering spatial relationships.</li>
  <li><strong>Common techniques</strong> include linear transformations, gamma correction, thresholding, histogram equalization, bitwise operations, and color space transformations.</li>
  <li><strong>Applications</strong>: These techniques are essential in image preprocessing, contrast enhancement, segmentation, and color analysis, making them fundamental tools in computer vision tasks.</li>
</ul>

<h1 id="3-histogram-equalization">3. Histogram Equalization</h1>

<p>Histogram equalization is a technique used in image processing to improve the contrast of an image by spreading out the most frequent intensity values. This is particularly useful in images that are either too dark or too bright, where the pixel values are concentrated in a narrow range.</p>

<h2 id="31-how-it-works">3.1 How It Works</h2>

<p><strong>1. Histogram Calculation</strong>:</p>
<ul>
  <li>The histogram of an image shows the distribution of pixel intensities. For a grayscale image, it counts how many pixels have each possible intensity value (0 to 255 for an 8-bit image).</li>
</ul>

<p><strong>2. Cumulative Distribution Function (CDF)</strong>:</p>
<ul>
  <li>The CDF is calculated from the histogram. It represents the cumulative sum of the histogram values, normalized to the range of the pixel values (0 to 255 for an 8-bit image). The CDF essentially shows the cumulative probability distribution of pixel intensities.</li>
</ul>

<p><strong>3. Transformation Function</strong>:</p>
<ul>
  <li>A transformation function is created using the CDF to map the original pixel intensities to new values. This function stretches the intensity values over the entire range (0 to 255), effectively redistributing the intensity values to enhance contrast.</li>
</ul>

<p><strong>4. Applying the Transformation</strong>:</p>
<ul>
  <li>The transformation function is applied to each pixel in the image, resulting in a new image with improved contrast.</li>
</ul>

<h2 id="32-example">3.2 Example</h2>

<h4 id="step-1-original-image-histogram">Step 1: Original Image Histogram</h4>

<p>Consider a simple 3x3 grayscale image with the following pixel values:</p>

\[\begin{bmatrix}
52 &amp; 55 &amp; 61 \\
59 &amp; 79 &amp; 61 \\
67 &amp; 75 &amp; 80
\end{bmatrix}\]

<ul>
  <li>The intensity values range from 52 to 80, which is a narrow range.</li>
</ul>

<h4 id="step-2-calculate-histogram">Step 2: Calculate Histogram</h4>

<p>Compute the histogram of the image. The histogram shows the frequency of each pixel value:</p>

\[\begin{array}{c|c}
\text{Intensity} &amp; \text{Frequency} \\
\hline
52 &amp; 1 \\
55 &amp; 1 \\
59 &amp; 1 \\
61 &amp; 2 \\
67 &amp; 1 \\
75 &amp; 1 \\
79 &amp; 1 \\
80 &amp; 1 \\
\end{array}\]

<h4 id="step-3-calculate-cumulative-distribution-function-cdf">Step 3: Calculate Cumulative Distribution Function (CDF)</h4>

<p>Calculate the CDF from the histogram. Normalize it so that the maximum CDF value corresponds to 255 (for an 8-bit image):</p>

\[\begin{array}{c|c|c}
\text{Intensity} &amp; \text{CDF} &amp; \text{Normalized CDF} \\
\hline
52 &amp; 1 &amp; \frac{1}{9} \times 255 = 28 \\
55 &amp; 2 &amp; \frac{2}{9} \times 255 = 56 \\
59 &amp; 3 &amp; \frac{3}{9} \times 255 = 85 \\
61 &amp; 5 &amp; \frac{5}{9} \times 255 = 141 \\
67 &amp; 6 &amp; \frac{6}{9} \times 255 = 170 \\
75 &amp; 7 &amp; \frac{7}{9} \times 255 = 198 \\
79 &amp; 8 &amp; \frac{8}{9} \times 255 = 226 \\
80 &amp; 9 &amp; \frac{9}{9} \times 255 = 255 \\
\end{array}\]

<h4 id="step-4-apply-the-transformation">Step 4: Apply the Transformation</h4>

<p>Using the normalized CDF values, map the original intensity values to the new ones:</p>

\[\begin{array}{c|c}
\text{Original Intensity} &amp; \text{New Intensity} \\
\hline
52 &amp; 28 \\
55 &amp; 56 \\
59 &amp; 85 \\
61 &amp; 141 \\
67 &amp; 170 \\
75 &amp; 198 \\
79 &amp; 226 \\
80 &amp; 255 \\
\end{array}\]

<p>The transformed image is:</p>

\[\begin{bmatrix}
28 &amp; 56 &amp; 141 \\
85 &amp; 226 &amp; 141 \\
170 &amp; 198 &amp; 255
\end{bmatrix}\]

<h4 id="step-5-resulting-image">Step 5: Resulting Image</h4>

<p>The resulting image has a much better contrast compared to the original. The intensity values now span a wider range (from 28 to 255), enhancing the visual quality.</p>

<h2 id="33-histogram-equalization-in-opencv">3.3 Histogram Equalization in OpenCV</h2>

<p>Here’s how you can perform histogram equalization using OpenCV:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">cv2</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="c1"># Load a grayscale image
</span><span class="n">image</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">imread</span><span class="p">(</span><span class="sh">'</span><span class="s">image.jpg</span><span class="sh">'</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">IMREAD_GRAYSCALE</span><span class="p">)</span>

<span class="c1"># Apply histogram equalization
</span><span class="n">equalized_image</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">equalizeHist</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

<span class="c1"># Display the original and equalized images
</span><span class="n">cv2</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="sh">'</span><span class="s">Original Image</span><span class="sh">'</span><span class="p">,</span> <span class="n">image</span><span class="p">)</span>
<span class="n">cv2</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="sh">'</span><span class="s">Equalized Image</span><span class="sh">'</span><span class="p">,</span> <span class="n">equalized_image</span><span class="p">)</span>

<span class="c1"># Plot the histograms
</span><span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">hist</span><span class="p">(</span><span class="n">image</span><span class="p">.</span><span class="nf">ravel</span><span class="p">(),</span> <span class="mi">256</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">256</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Original Histogram</span><span class="sh">'</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">hist</span><span class="p">(</span><span class="n">equalized_image</span><span class="p">.</span><span class="nf">ravel</span><span class="p">(),</span> <span class="mi">256</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">256</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Equalized Histogram</span><span class="sh">'</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="n">cv2</span><span class="p">.</span><span class="nf">waitKey</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">cv2</span><span class="p">.</span><span class="nf">destroyAllWindows</span><span class="p">()</span>
</code></pre></div></div>

<h2 id="34--keypoints">3.4  Keypoints</h2>

<ul>
  <li><strong>Histogram equalization</strong> is a technique for enhancing image contrast by redistributing the intensity values.</li>
  <li><strong>Steps involved</strong>: Calculating the histogram, deriving the CDF, and applying a transformation function based on the CDF.</li>
  <li><strong>Result</strong>: The output image has improved contrast, with intensity values spread more evenly across the available range.</li>
  <li><strong>Applications</strong>: Useful in image enhancement tasks, especially for images with poor contrast due to lighting conditions.</li>
</ul>

<h1 id="4-histogram-equalization-vs-matching">4. Histogram Equalization vs Matching</h1>

<p><strong>Histogram Equalization</strong> and <strong>Histogram Matching (also known as Histogram Specification)</strong> are both techniques used in image processing to modify the contrast of images, but they serve different purposes and achieve different results.</p>

<h2 id="41-histogram-equalization">4.1 Histogram Equalization</h2>

<ul>
  <li>
    <p><strong>Purpose</strong>: Histogram equalization is used to enhance the contrast of an image by redistributing the intensity values so that they span a broader range. This process tends to make the image’s histogram as uniform as possible, thereby improving visibility in underexposed or overexposed regions.</p>
  </li>
  <li><strong>Operation</strong>:
    <ul>
      <li>The process involves computing the histogram of the image, calculating the cumulative distribution function (CDF), and then using the CDF to map the original intensity values to new values that are spread out more evenly across the intensity range.</li>
    </ul>
  </li>
  <li>
    <p><strong>Result</strong>: The output image typically has better contrast, but the exact shape of the histogram is not controlled—it’s determined by the original image’s content and the equalization process.</p>
  </li>
  <li><strong>Applications</strong>:
    <ul>
      <li>Enhancing visibility in images with poor lighting conditions.</li>
      <li>Preparing images for feature extraction in computer vision tasks by improving contrast.</li>
    </ul>
  </li>
</ul>

<h2 id="42-histogram-matching-histogram-specification">4.2 Histogram Matching (Histogram Specification)</h2>

<ul>
  <li>
    <p><strong>Purpose</strong>: Histogram matching is used to transform the histogram of one image so that it resembles the histogram of another image (the reference image). Unlike histogram equalization, which spreads the histogram across the intensity range, histogram matching adjusts the histogram to follow a specific distribution.</p>
  </li>
  <li><strong>Operation</strong>:
    <ul>
      <li>The process involves computing the histograms of both the source and reference images, calculating their CDFs, and then mapping the source image’s intensities to match the CDF of the reference image. This ensures that the final image has a histogram that closely resembles the reference histogram.</li>
    </ul>
  </li>
  <li>
    <p><strong>Result</strong>: The output image has a histogram that matches the shape of the reference image’s histogram, which can be useful for specific tasks where consistent lighting, color, or intensity distribution is required across different images.</p>
  </li>
  <li><strong>Applications</strong>:
    <ul>
      <li>Matching images for consistent appearance in tasks like image stitching, where images need to look uniform.</li>
      <li>Preprocessing images in computer vision tasks where the goal is to maintain a consistent feature distribution across multiple images.</li>
    </ul>
  </li>
</ul>

<h2 id="43-differences-between-histogram-equalization-and-histogram-matching">4.3 Differences Between Histogram Equalization and Histogram Matching</h2>

<ul>
  <li><strong>Objective</strong>:
    <ul>
      <li><strong>Histogram Equalization</strong>: Aims to enhance contrast by spreading pixel intensities evenly across the histogram range.</li>
      <li><strong>Histogram Matching</strong>: Aims to adjust the pixel intensity distribution of one image to match a target histogram.</li>
    </ul>
  </li>
  <li><strong>Outcome</strong>:
    <ul>
      <li><strong>Histogram Equalization</strong>: Results in an image with a generally uniform histogram, improving contrast but potentially altering the appearance in an unpredictable way.</li>
      <li><strong>Histogram Matching</strong>: Results in an image with a specific histogram shape, tailored to match the reference image, preserving the relative intensity relationships.</li>
    </ul>
  </li>
  <li><strong>Control</strong>:
    <ul>
      <li><strong>Histogram Equalization</strong>: Less control over the final appearance; it is automatic and adapts to the image content.</li>
      <li><strong>Histogram Matching</strong>: More control over the final appearance; it follows the desired histogram provided by the reference image.</li>
    </ul>
  </li>
</ul>

<h2 id="44-importance-in-computer-vision">4.4 Importance in Computer Vision</h2>

<h4 id="histogram-equalization">Histogram Equalization</h4>

<ul>
  <li>
    <p><strong>Enhancing Visibility</strong>: Improves the visibility of details in images with poor lighting or contrast. This is crucial in tasks like object detection, medical imaging, and surveillance, where clear visibility of features is necessary.</p>
  </li>
  <li>
    <p><strong>Preprocessing</strong>: Equalization can standardize the contrast levels across a dataset, making features more consistent and improving the performance of machine learning models.</p>
  </li>
  <li>
    <p><strong>Dynamic Range Compression</strong>: In high-dynamic-range imaging, equalization helps in compressing the dynamic range, allowing better visualization on standard displays.</p>
  </li>
</ul>

<h4 id="histogram-matching">Histogram Matching</h4>

<ul>
  <li>
    <p><strong>Consistency Across Images</strong>: Ensures a uniform appearance across a set of images, which is vital in tasks like image stitching, where differences in lighting can cause visible seams between images.</p>
  </li>
  <li>
    <p><strong>Domain Adaptation</strong>: In machine learning, especially in transfer learning, histogram matching can be used to adapt the input data to the statistical distribution of the training data, improving model performance.</p>
  </li>
  <li>
    <p><strong>Style Transfer</strong>: In artistic and photographic applications, histogram matching can be used to impose a particular style or mood by matching the histogram to that of a desired image.</p>
  </li>
</ul>

<h2 id="45-example">4.5 Example</h2>

<p>Here’s an example of how you can perform both histogram equalization and histogram matching using OpenCV:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">cv2</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="c1"># Load the source image
</span><span class="n">source_image</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">imread</span><span class="p">(</span><span class="sh">'</span><span class="s">source_image.jpg</span><span class="sh">'</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">IMREAD_GRAYSCALE</span><span class="p">)</span>

<span class="c1"># Load the reference image (for histogram matching)
</span><span class="n">reference_image</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">imread</span><span class="p">(</span><span class="sh">'</span><span class="s">reference_image.jpg</span><span class="sh">'</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">IMREAD_GRAYSCALE</span><span class="p">)</span>

<span class="c1"># Apply histogram equalization to the source image
</span><span class="n">equalized_image</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">equalizeHist</span><span class="p">(</span><span class="n">source_image</span><span class="p">)</span>

<span class="c1"># Histogram matching (using OpenCV's matchHistograms if available in your version)
</span><span class="n">matched_image</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">matchTemplate</span><span class="p">(</span><span class="n">source_image</span><span class="p">,</span> <span class="n">reference_image</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">HISTCMP_CORREL</span><span class="p">)</span>

<span class="c1"># Display the images and their histograms
</span><span class="n">images</span> <span class="o">=</span> <span class="p">[</span><span class="n">source_image</span><span class="p">,</span> <span class="n">equalized_image</span><span class="p">,</span> <span class="n">matched_image</span><span class="p">]</span>
<span class="n">titles</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">Source Image</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Histogram Equalization</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Histogram Matching</span><span class="sh">'</span><span class="p">]</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="sh">'</span><span class="s">gray</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="n">titles</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">axis</span><span class="p">(</span><span class="sh">'</span><span class="s">off</span><span class="sh">'</span><span class="p">)</span>
    
    <span class="n">plt</span><span class="p">.</span><span class="nf">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">4</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">hist</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="nf">ravel</span><span class="p">(),</span> <span class="mi">256</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">256</span><span class="p">])</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="si">{</span><span class="n">titles</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s"> Histogram</span><span class="sh">'</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div>

<h2 id="46-keypoints">4.6 Keypoints</h2>

<ul>
  <li><strong>Histogram Equalization</strong> is used to improve contrast across the entire image, making it beneficial for enhancing visibility and preparing images for feature extraction in computer vision.</li>
  <li><strong>Histogram Matching</strong> is used to ensure consistency across images by adjusting the histogram of one image to match that of another, useful in tasks requiring uniform appearance or specific intensity distributions.</li>
  <li>Both techniques play crucial roles in preprocessing, ensuring that images are suitable for further analysis or display, depending on the specific requirements of the task.</li>
</ul>

<h1 id="5-morphology-operators">5. Morphology Operators</h1>

<p>Morphological operators are fundamental tools in image processing that are based on the shape and structure of objects within an image. They are primarily used for processing binary images but can also be applied to grayscale images. These operations manipulate the geometrical structure of an image and are particularly useful for tasks such as noise removal, object detection, and image segmentation in computer vision.</p>

<h2 id="51-key-morphological-operators">5.1 Key Morphological Operators</h2>

<p><strong>1. Erosion</strong>:</p>
<ul>
  <li><strong>Operation</strong>: Erosion shrinks the white regions (foreground) in a binary image. It removes pixels on object boundaries. The basic idea is to erode away the boundaries of the foreground object.</li>
  <li><strong>How It Works</strong>: A structuring element (a small binary matrix) is slid over the image, and the pixel in the original image is set to the minimum value (for binary, this is typically 0) covered by the structuring element.</li>
  <li><strong>Use Cases</strong>: Removing small noise, detaching connected objects, and reducing object size.</li>
</ul>

<p><strong>2. Dilation</strong>:</p>
<ul>
  <li><strong>Operation</strong>: Dilation is the opposite of erosion; it expands the white regions (foreground). It adds pixels to the boundaries of objects in an image.</li>
  <li><strong>How It Works</strong>: The structuring element is slid over the image, and the pixel is set to the maximum value (for binary, typically 1) covered by the structuring element.</li>
  <li><strong>Use Cases</strong>: Filling small holes, connecting disjoint objects, and increasing object size.</li>
</ul>

<p><strong>3. Opening</strong>:</p>
<ul>
  <li><strong>Operation</strong>: Opening is a sequence of erosion followed by dilation. It is used to remove small objects from the foreground.</li>
  <li><strong>How It Works</strong>: Erosion removes small objects or noise, and dilation restores the shape of the remaining objects.</li>
  <li><strong>Use Cases</strong>: Removing noise while preserving the shape and size of larger objects, smoothing the outline of objects.</li>
</ul>

<p><strong>4. Closing</strong>:</p>
<ul>
  <li><strong>Operation</strong>: Closing is a sequence of dilation followed by erosion. It is used to fill small holes in the foreground.</li>
  <li><strong>How It Works</strong>: Dilation fills small holes or gaps in the object, and erosion restores the shape of the object.</li>
  <li><strong>Use Cases</strong>: Filling small holes and gaps, smoothing the boundaries of objects, closing small breaks or cracks.</li>
</ul>

<p><strong>5. Morphological Gradient</strong>:</p>
<ul>
  <li><strong>Operation</strong>: The morphological gradient is the difference between the dilation and erosion of an image. It highlights the edges of objects.</li>
  <li><strong>Use Cases</strong>: Edge detection, highlighting object boundaries.</li>
</ul>

<p><strong>6. Top-hat Transform</strong>:</p>
<ul>
  <li><strong>Operation</strong>: The top-hat transform is the difference between the original image and its opening. It is used to extract small elements and details from an image.</li>
  <li><strong>Use Cases</strong>: Enhancing features, extracting small objects.</li>
</ul>

<p><strong>7. Black-hat Transform</strong>:</p>
<ul>
  <li><strong>Operation</strong>: The black-hat transform is the difference between the closing of the image and the original image. It is used to highlight small dark regions on a bright background.</li>
  <li><strong>Use Cases</strong>: Detecting dark features on a bright background.</li>
</ul>

<h2 id="52-importance-in-computer-vision">5.2 Importance in Computer Vision</h2>

<p><strong>1. Noise Removal</strong>:</p>
<ul>
  <li>Morphological operators like opening and closing are effective in removing noise from images, particularly in binary images where small noise elements need to be removed without affecting the main objects.</li>
</ul>

<p><strong>2. Shape Extraction and Analysis</strong>:</p>
<ul>
  <li>These operators are fundamental in extracting and analyzing the shape of objects within an image. For example, erosion can be used to find the skeleton of objects, while dilation can help connect disjointed components.</li>
</ul>

<p><strong>3. Object Detection and Segmentation</strong>:</p>
<ul>
  <li>Morphological operations are crucial in preprocessing for object detection and segmentation tasks. For example, closing can help fill gaps in segmented regions, making objects easier to identify.</li>
</ul>

<p><strong>4. Edge Detection</strong>:</p>
<ul>
  <li>The morphological gradient is useful for detecting edges and boundaries in an image, which is often a critical step in computer vision pipelines.</li>
</ul>

<p><strong>5. Image Enhancement</strong>:</p>
<ul>
  <li>Operators like the top-hat and black-hat transforms are used to enhance specific features in an image, such as extracting bright or dark features against a uniform background.</li>
</ul>

<h2 id="53-example">5.3 Example</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">cv2</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="c1"># Load a binary image
</span><span class="n">image</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">imread</span><span class="p">(</span><span class="sh">'</span><span class="s">image.jpg</span><span class="sh">'</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">IMREAD_GRAYSCALE</span><span class="p">)</span>

<span class="c1"># Define a structuring element
</span><span class="n">kernel</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">ones</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="n">uint8</span><span class="p">)</span>

<span class="c1"># Apply erosion
</span><span class="n">eroded</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">erode</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">iterations</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># Apply dilation
</span><span class="n">dilated</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">dilate</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">iterations</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># Apply opening
</span><span class="n">opened</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">morphologyEx</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">MORPH_OPEN</span><span class="p">,</span> <span class="n">kernel</span><span class="p">)</span>

<span class="c1"># Apply closing
</span><span class="n">closed</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">morphologyEx</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">MORPH_CLOSE</span><span class="p">,</span> <span class="n">kernel</span><span class="p">)</span>

<span class="c1"># Apply morphological gradient
</span><span class="n">gradient</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">morphologyEx</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">MORPH_GRADIENT</span><span class="p">,</span> <span class="n">kernel</span><span class="p">)</span>

<span class="c1"># Display the results
</span><span class="n">cv2</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="sh">'</span><span class="s">Original Image</span><span class="sh">'</span><span class="p">,</span> <span class="n">image</span><span class="p">)</span>
<span class="n">cv2</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="sh">'</span><span class="s">Eroded Image</span><span class="sh">'</span><span class="p">,</span> <span class="n">eroded</span><span class="p">)</span>
<span class="n">cv2</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="sh">'</span><span class="s">Dilated Image</span><span class="sh">'</span><span class="p">,</span> <span class="n">dilated</span><span class="p">)</span>
<span class="n">cv2</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="sh">'</span><span class="s">Opened Image</span><span class="sh">'</span><span class="p">,</span> <span class="n">opened</span><span class="p">)</span>
<span class="n">cv2</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="sh">'</span><span class="s">Closed Image</span><span class="sh">'</span><span class="p">,</span> <span class="n">closed</span><span class="p">)</span>
<span class="n">cv2</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="sh">'</span><span class="s">Morphological Gradient</span><span class="sh">'</span><span class="p">,</span> <span class="n">gradient</span><span class="p">)</span>

<span class="n">cv2</span><span class="p">.</span><span class="nf">waitKey</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">cv2</span><span class="p">.</span><span class="nf">destroyAllWindows</span><span class="p">()</span>
</code></pre></div></div>

<h2 id="54-keypoints">5.4 Keypoints</h2>

<ul>
  <li><strong>Morphological operators</strong> are essential tools in image processing that manipulate the structure of objects in binary and grayscale images.</li>
  <li><strong>Key operators</strong> include erosion, dilation, opening, closing, and more specialized transforms like the morphological gradient and top-hat transform.</li>
  <li><strong>Importance</strong>: These operators are crucial in tasks like noise removal, object detection, shape analysis, and edge detection, making them fundamental in many computer vision applications.</li>
</ul>
</section>
            </div><div class="search-results">
    <div class="has-results">
        <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
        <ul class="search-results-list"></ul>
    </div>
    <div class="no-results">
        <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
    </div>
</div></div>
    </div>
</div>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.7.1/jquery.min.js"></script>

<!-- introduce js_includes_ex support -->

<script>

    // Libraries to add dynamic tags below using .html files
    
    
    window.sciptsLib = new Map();
    window.cssLib = new Map();
    window.scipts = new Map();
    window.links = new Map();
    var jsIdIdx = 0;
    var cssIdIdx = 0;
    
    window.sciptsLib.set('bootstrap', [
        {uri: '//cdn.jsdelivr.net/npm/popper.js@1.12.9/dist/umd/popper.min.js'},
        {uri: '//cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js'}
    ]);
    window.cssLib.set('bootstrap', {uri: '//cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css'});
    
    window.sciptsLib.set('prism', {uri: '/ds/aml/assets/libs/prism/prism.js', defer: false});
    window.cssLib.set('prism', {uri: '/ds/aml/assets/libs/prism/prism.css', defer: false});

    //window.sciptsLib.set('xmind', {uri: '/ds/aml/assets/xmind/umd/xmind-embed-viewer.js', defer: false});
    
    // animate is included in head.html to support logo animation in navbar
    // window.cssLib.set('animate', {uri: '//cdnjs.cloudflare.com/ajax/libs/animate.css/4.1.1/animate.min.css'});
    
    // Add the script tags before the following element
    var getbookStyleElement = document.getElementById("gitbook_style")

    // Adding script tags to externally link js
        keyName = `prism_js`

        if (!window.scipts.get(keyName)) {

            // Get the links from sciptsLib
            jsLinks = window.sciptsLib.get( 'prism');

            if (jsLinks instanceof Array) {
            
                let scriptTags = []            
                
                for (i in jsLinks) {
                    scriptTag = document.createElement("script")
                    scriptTag.src = jsLinks[i]['uri'];                    
                    scriptTag.defer = ('defer' in jsLinks[i]) ? jsLinks[i]['defer'] : true;
                    scriptTag.id =  `prism_js_${jsIdIdx++}`;
                    document.head.insertBefore(scriptTag, getbookStyleElement)
                    
                    scriptTags.push(scriptTag);
                    console.log(scriptTag)
                }

                // Add script tags to window.scripts map object
                window.scipts.set(keyName, scriptTags)
            
            } else if (window.sciptsLib.has( 'prism')) {

                scriptTag = document.createElement("script");
                // console.log("sadasd", prism, jsLinks);
                scriptTag.src = jsLinks['uri'];
                scriptTag.defer = ('defer' in jsLinks) ? jsLinks['defer'] : true;
                scriptTag.id =  `prism_js_${jsIdIdx++}`;
                document.head.insertBefore(scriptTag, getbookStyleElement)
                console.log(scriptTag)

                // Add script tag to window.scripts map object
                window.scipts.set(keyName, scriptTag);
            }
        }


        // Adding link tags to externally link css
        keyName = `prism_css`

        if (!window.scipts.get(keyName)) {

            // Get the links from cssLib
            cssLinks = window.cssLib.get( 'prism');            
            
            if (cssLinks instanceof Array) {
            
                let cssLinkTags = []            
                
                for (i in cssLinks) {
                    cssLinkTag = document.createElement("script")
                    cssLinkTag.href = cssLinks[i]['uri'];
                    cssLinkTag.defer = ('defer' in cssLinks[i]) ? cssLinks[i]['defer'] : true;
                    cssLinkTag.id =  `prism_css_${cssIdIdx++}`;
                    cssLinkTag.rel = 'stylesheet';
                    document.head.insertBefore(cssLinkTag, getbookStyleElement)
                    
                    cssLinkTags.push(cssLinkTag);
                    console.log(cssLinkTag)
                }

                // Add script tags to window.scripts map object
                window.scipts.set(keyName, cssLinkTags)
            
            } else if (window.cssLib.has( 'prism')) {

                cssLinkTag = document.createElement("link")
                cssLinkTag.href = cssLinks['uri'];
                cssLinkTag.defer = ('defer' in cssLinks) ? cssLinks['defer'] : true;
                cssLinkTag.id =  `prism_css_${cssIdIdx++}`;
                cssLinkTag.rel = 'stylesheet';
                document.head.insertBefore(cssLinkTag, getbookStyleElement)

                console.log(cssLinkTag)

                // Add script tag to window.scripts map object
                window.scipts.set(keyName, cssLinkTag);
            }
        }    
        
    // Adding script tags to externally link js
        keyName = `mathjax_js`

        if (!window.scipts.get(keyName)) {

            // Get the links from sciptsLib
            jsLinks = window.sciptsLib.get( 'mathjax');

            if (jsLinks instanceof Array) {
            
                let scriptTags = []            
                
                for (i in jsLinks) {
                    scriptTag = document.createElement("script")
                    scriptTag.src = jsLinks[i]['uri'];                    
                    scriptTag.defer = ('defer' in jsLinks[i]) ? jsLinks[i]['defer'] : true;
                    scriptTag.id =  `mathjax_js_${jsIdIdx++}`;
                    document.head.insertBefore(scriptTag, getbookStyleElement)
                    
                    scriptTags.push(scriptTag);
                    console.log(scriptTag)
                }

                // Add script tags to window.scripts map object
                window.scipts.set(keyName, scriptTags)
            
            } else if (window.sciptsLib.has( 'mathjax')) {

                scriptTag = document.createElement("script");
                // console.log("sadasd", mathjax, jsLinks);
                scriptTag.src = jsLinks['uri'];
                scriptTag.defer = ('defer' in jsLinks) ? jsLinks['defer'] : true;
                scriptTag.id =  `mathjax_js_${jsIdIdx++}`;
                document.head.insertBefore(scriptTag, getbookStyleElement)
                console.log(scriptTag)

                // Add script tag to window.scripts map object
                window.scipts.set(keyName, scriptTag);
            }
        }


        // Adding link tags to externally link css
        keyName = `mathjax_css`

        if (!window.scipts.get(keyName)) {

            // Get the links from cssLib
            cssLinks = window.cssLib.get( 'mathjax');            
            
            if (cssLinks instanceof Array) {
            
                let cssLinkTags = []            
                
                for (i in cssLinks) {
                    cssLinkTag = document.createElement("script")
                    cssLinkTag.href = cssLinks[i]['uri'];
                    cssLinkTag.defer = ('defer' in cssLinks[i]) ? cssLinks[i]['defer'] : true;
                    cssLinkTag.id =  `mathjax_css_${cssIdIdx++}`;
                    cssLinkTag.rel = 'stylesheet';
                    document.head.insertBefore(cssLinkTag, getbookStyleElement)
                    
                    cssLinkTags.push(cssLinkTag);
                    console.log(cssLinkTag)
                }

                // Add script tags to window.scripts map object
                window.scipts.set(keyName, cssLinkTags)
            
            } else if (window.cssLib.has( 'mathjax')) {

                cssLinkTag = document.createElement("link")
                cssLinkTag.href = cssLinks['uri'];
                cssLinkTag.defer = ('defer' in cssLinks) ? cssLinks['defer'] : true;
                cssLinkTag.id =  `mathjax_css_${cssIdIdx++}`;
                cssLinkTag.rel = 'stylesheet';
                document.head.insertBefore(cssLinkTag, getbookStyleElement)

                console.log(cssLinkTag)

                // Add script tag to window.scripts map object
                window.scipts.set(keyName, cssLinkTag);
            }
        }    
        
    

</script>



<script>
window.MathJax = {
  tex: {
    inlineMath: [ ['$', '$'], ['\\(', '\\)'] ]
  },
  svg: {
    fontCache: 'global'
  }
};
</script>
<script
  type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
</script>





<!-- introduce mathjax support -->
<script>
    function fixes_chrome_anchors() {
        let chrome = /Chrome/.test(navigator.userAgent) && /Google Inc/.test(navigator.vendor);
        if (window.location.hash && chrome) {
            setTimeout(function () {
                var hash = window.location.hash;
                window.location.hash = "";
                window.location.hash = hash;
            }, 300);
        }
    }

    if (document.readyState === "loading") {
        // Loading hasn't finished yet
        document.addEventListener("DOMContentLoaded", fixes_chrome_anchors);
    } else {
        // `DOMContentLoaded` has already fired
        fixes_chrome_anchors();
    }
</script>


                        <a href="/ds/aml/" class="navigation navigation-prev navigation-unique" aria-label="Previous page: Wiki | Advance Machine Learning"> <!-- class="hide_element" -->
                            <i class="fa fa-angle-left"></i>
                        </a>
                    

                    
                        <a href="/ds/aml/image_analysis/1_ima_2_filters/" class="navigation navigation-next navigation-unique" aria-label="Next page: 2. Filters"> <!-- class="hide_element" -->
                            <i class="fa fa-angle-right"></i>
                        </a>
                    
                    <div class="copyright"><span>&copy; 2024 Intelligent Mind Labs, Inc. All rights reserved.</span>.</div>
                </div>
            </div>

            <script>
                // div "book" element's content is the only content refreshed when nav link is pressed.
                // This functionality is implemented in "gitbook.js" and "theme.js"
                // head.html and footer.html will not be called again and again when a new nav link is clicked
                // Gitbook js is optimized to dynamically change content inside div "book" element.
                // Due to this: script put in the footer will only be called once,
                // which is the very first time the page is loaded by entering
                // the web address in the address bar in the browser
                // 
                $ = jQuery;
                $(function() {
                    // spinnerHide();
                    // setTimeout(spinnerHide, 200);
           
                    $('.childBtn').on('click', function(event) {
                        event.stopImmediatePropagation(); // To prevent following the link (optional)
                        window.location = $(this).attr('link');
                    });

                    $('.parentBtn').on('click', function(event) {
                        window.location = $(this).attr('link');
                    });
                });
            </script>

            <script>
            var gitbook = gitbook || [];
            gitbook.push(function() {
                gitbook.page.hasChanged({
    "page": {
        "title": "Introduction",
        "level": "1.1",
        "depth": 1,
        
        "next": {
            "title": "2. Filters",
            "level": "1.2",
            "depth": 1,
            "path": "_4_problem_domains/1_ima_2_filters.md",
            "ref": "_4_problem_domains/1_ima_2_filters.md",
            "articles": []
        },
        
        "dir": "ltr"
    },    "config": {
        "plugins": ["fontsettings", "highlight", "livereload", "lunr", "search", "sharing", "theme-default", "livereload"],
        "styles": {
            "ebook": "styles/ebook.css",
            "epub": "styles/epub.css",
            "mobi": "styles/mobi.css",
            "pdf": "styles/pdf.css",
            "print": "styles/print.css",
            "website": "styles/website.css"
        },
        "pluginsConfig": {
            "expandable-chapter-small2": {
                "articlesExpand": true,
            },
            "fontsettings": {
                "family": "sans",
                "size": 2,
                "theme": "white"
            },
            "highlight": {},
            "livereload": {},
            "lunr": {
                "ignoreSpecialCharacters": false,
                "maxIndexSize": 1000000
            },
            "search": {},            "sharing": {
                "facebook": true,

                "google": false,

                "github": true,
              
                "github_link": "https://github.com",
              

                "telegram": false,
                "telegram_link": "https://t.me",

                "instapaper": false,

                "twitter": true,
              

                "vk": false,

                "weibo": false,

                "all": ["facebook", "google", "twitter", "weibo", "instapaper", "github", "telegram"]
            },
"theme-default": {
                "showLevel": false,
                "styles": {
                    "ebook": "styles/ebook.css",
                    "epub": "styles/epub.css",
                    "mobi": "styles/mobi.css",
                    "pdf": "styles/pdf.css",
                    "print": "styles/print.css",
                    "website": "styles/website.css"
                }
            },
        },
        "theme": "default",
        "author": "Intelligent Mind Labs",
        "pdf": {
            "pageNumbers": true,
            "fontSize": 12,
            "fontFamily": "Arial",
            "paperSize": "a4",
            "chapterMark": "pagebreak",
            "pageBreaksBefore": "/",
            "margin": {
                "right": 62,
                "left": 62,
                "top": 56,
                "bottom": 56
            }
        },
        "structure": {
            "langs": "LANGS.md",
            "readme": "README.md",
        },
        "variables": {},
        "title": "Wiki | Advance Machine Learning",
        "language": "en",
        "gitbook": "*"
    },
    "file": {
        "path": "_4_problem_domains/1_ima_1_basics.md",
        "mtime": "2019-04-27 00:00:00 +0800",
        "type": "markdown"
    },
    "gitbook": {
        "version": "3.2.3",
        "time": "2024-08-20 15:29:14 +0800"
    },
    "basePath": "/ds/aml",
    "book": {
        "language": ""
    }
});
            });

            </script>
        </div><script src="/ds/aml/assets/gitbook/gitbook.js"></script>
<script src="/ds/aml/assets/gitbook/theme.js"></script>

<script src="/ds/aml/assets/gitbook/gitbook-plugin-back-to-top-button/plugin.js" async=""></script>
<!-- <script src="/ds/aml/assets/gitbook/gitbook-plugin-copy-code-button/toggle.js"></script> -->
<script src="/ds/aml/assets/gitbook/gitbook-plugin-expandable-chapters-small2/expandable-chapters-small.js"></script>
<script src="/ds/aml/assets/gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
<script src="/ds/aml/assets/gitbook/gitbook-plugin-search-pro/jquery.mark.min.js" defer=""></script>
<script src="/ds/aml/assets/gitbook/gitbook-plugin-search-pro/search.js" defer=""></script>
<script src="/ds/aml/assets/gitbook/gitbook-plugin-sharing/buttons.js" defer=""></script>
<script src="/ds/aml/assets/gitbook/gitbook-plugin-splitter/splitter.js" defer=""></script>




<!--
<script src="../gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
<script src="../gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
<script src="../gitbook/gitbook-plugin-search/search-engine.js"></script>
<script src="../gitbook/gitbook-plugin-search/search.js"></script>
-->



<script>
function spinnerHide() {
    $(".spinner-container").removeClass("show_element");
    $(".spinner-container").addClass("hide_element");
    $(".spinner-container").addClass("display_none");
    

    $("#book-search-results").removeClass("hide_element");
    $("#book-search-results").addClass("show_element");

    $(".navigation.navigation-next").removeClass("hide_element");
    $(".navigation.navigation-next").addClass("show_element");

    $(".navigation.navigation-prev").removeClass("hide_element");
    $(".navigation.navigation-prev").addClass("show_element");
}        
</script><!-- trackers --><!-- google analytics --><!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-V3WBTFTQWG"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-V3WBTFTQWG');
</script>
</body>
</html>